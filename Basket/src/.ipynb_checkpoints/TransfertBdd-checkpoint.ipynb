{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Notebook de transfert des donnees du site nba.com depuis le site ou un fichier intermediaire**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import sys, os, re, time #c'est pas propre mais pour le moment pour importer mes modules perso dans le notebook je ne sais pas faire\n",
    "sys.path.append(r'C:\\Users\\martin.schoreisz\\git\\Outils\\Outils\\Martin_Perso')\n",
    "import Connexion_Transfert as ct\n",
    "\n",
    "from datetime import datetime\n",
    "from TelechargementDonnees import JoueursSiteNba, DriverFirefox, gererCookie,simplifierNomJoueur\n",
    "from sqlalchemy import MetaData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Données de joueurs \n",
    "Il s'agit de transfere dans le cas des donnees de joueuer telechargees en amont, ou d'ajouter des joueurs non presents au moment d'insertion de match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">## 1.1 Enumerations des types de position\n",
    "A creer a la main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ct.ConnexionBdd('basket','maison') as c : \n",
    "    pd.DataFrame({'id_position_terrain':['F', 'G', 'C', 'C-F', 'F-G', 'G-F', 'F-C','NC'], \n",
    "              'nom_position_terrain':['Forward ; 3 ; ailier', 'Guard ; 1 ou 2  ; meneur ou arriere', \n",
    "                                      'Center ; 5 ; Pivot' ,'Power Forward ; 4 ; ailier Fort', \n",
    "                                      'Shooting Guard ; 2 ; arriere', 'Shooting Guard ; 2 ; arriere',\n",
    "                                      'Power Forward ; 4 ; ailier Fort', 'Non connue']}).to_sql(\n",
    "        'enum_position_terrain', c.sqlAlchemyConn, schema='donnees_source', if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## 1.2 Donnees chargees depuis la page internet\n",
    "Là ce n'est que le premier import, on ne gère pas la mise à jour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation de la classe si import depuis le net\n",
    "pagejoueuer=JoueursSiteNba(urlPageJoueurs='https://www.nba.com/player/1630173/precious-achiuwa',typeExport='One' ) #joueur unique\n",
    "pagejoueuer=JoueursSiteNba #joueurs multiples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagejoueuer.dfJoueurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#si import depuis json\n",
    "Joueur=pd.read_json(r'C:\\Users\\martin.schoreisz\\git\\Basket\\Basket\\data\\Joueurs_saison_2020-2021\\joueurs.json')\n",
    "#correction format date\n",
    "Joueur.date_entree_nba=Joueur.date_entree_nba.apply(lambda x : pd.to_datetime(x,unit='ms'))\n",
    "Joueur.date_naissance=Joueur.date_naissance.apply(lambda x : pd.to_datetime(x,unit='ms'))\n",
    "#si besoin correction position bizrre car inconnues sur le net (normalenet pris en cmpte en amont dans nouvelle versions)\n",
    "Joueur.loc[~Joueur.id_position_terrain.isin(['F', 'G', 'C', 'C-F', 'F-G', 'G-F', 'F-C','NC']),'id_position_terrain']='NC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ct.ConnexionBdd('basket','maison') as c : \n",
    "    #remmplacer pagejoueuer.dfJoueurs par Joueur si import Json\n",
    "    Joueur[['nom','id_position_terrain','taille', 'poids','date_entree_nba','nom_simple']].to_sql(\n",
    "        'joueur', c.sqlAlchemyConn, schema='donnees_source', if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Données d'équipe\n",
    "On utilise les données de joueurs pour faire la liste des equipes, et on complete avec les divisions et conférence, puis on transfere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicoNom={'MIA':'Miami Heat','MIL':'Milwaukee Bucks','NOP':'New-Orleans Pelicans','SAS':'San-Antonio Spurs',\n",
    "'PHX':'Phoenix','MEM':'Memphis Grizzlies',    'BKN':'Brooklyn Nets','ORL':'Orlando Magic','LAL':'LosAngeles Lakers','POR':'Portland TrailBlazzers','TOR':'Toronto Raptors','CHI':'Chicago Bulls',\n",
    "'OKC':'Oklahoma City Thunder','WAS':'Washington Wizards','UTA':'Utah Jazz','SAC':'Sacramento Kings','CHA':'Charlotte Hornets','NYK':'New-York Knicks','DEN':'Denver Nuggets',\n",
    "'LAC':'Los Angeles Clippers','GSW':'Golden State Warriors','MIN':'Minessota TimberWolves','DET':'Detroit Pistons','DAL':'Dallas Mavericks',\n",
    "'IND':'Indiana Pacers','ATL':'Atlanta Hawks','CLE':'Cleveland Cavaliers','PHI':'Philadelphia Sixers','BOS':'Boston Celtics','HOU':'Houston Rockets'}\n",
    "list_equipe=dicoNom.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicoDivision={'Central Division': ['MIL', 'CHI', 'IND', 'CLE', 'DET'],'Atlantic Division': ['BOS', 'BKN', 'NYK', 'TOR', \n",
    "'PHI'],'Southeast Division' : ['MIA', 'ORL', 'WAS', 'CHA', 'ATL'],'Southwest Division': ['SAS', 'HOU', 'DAL', 'NOP', \n",
    "'MEM'],'Northwest Division' : ['DEN', 'MIN', 'OKC', 'POR', 'UTA'],'Pacific Division' : ['LAC', 'LAL', 'PHX', 'GSW', 'SAC']}\n",
    "listDivision=[k for e in list_equipe for k,v in dicoDivision.items()  if e in v] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicoConference={'Ouest' : ['SAS', 'HOU', 'DAL', 'NOP', 'MEM','DEN', 'MIN', 'OKC', 'POR', 'UTA','LAC', 'LAL', 'PHX', \n",
    "    'GSW', 'SAC'],'Est':['MIL', 'CHI', 'IND', 'CLE', 'DET','BOS', 'BKN', 'NYK', 'TOR', 'PHI','MIA', \n",
    "                         'ORL', 'WAS', 'CHA', 'ATL']}\n",
    "\n",
    "listConference=[k for e in list_equipe for k,v in dicoConference.items()  if e in v] \n",
    "listNom=[v for k,v in dicoNom.items() for e in list_equipe if k==e] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ct.ConnexionBdd('basket','boulot') as c : \n",
    "    pd.DataFrame({'id_equipe':list_equipe,'nom_equipe': listNom,\n",
    "              'conference':listConference, 'division':listDivision}).to_sql(\n",
    "        'equipe', c.sqlAlchemyConn, schema='donnees_source', if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Données de match\n",
    "Dans un premier temp on va lire les fichiers csv stcokés [ici](C:\\Users\\martin.schoreisz\\Documents\\AffairesEnCours\\temp\\basket)\n",
    "L'idée c'est d'avoir une classe match, qui va regrouper : \n",
    "- les df de matchs, statjoueur, stat\n",
    "- va falloir gérer les contrats : \n",
    "    - l'id_joueur n'est pas dans contrat : -> on cree une ligne avec id_equip, id_joueur, date_debut_contrat à  minima\n",
    "    - l'id_joueur est dans contrat : \n",
    "        - trouver la date la plus recente\n",
    "        - obtenir l'equipe en cours\n",
    "        - comparer avec equipe actuelle : \n",
    "            - equipe identiques : on fait rien\n",
    "            - equipe differente : \n",
    "                - update date_fin_contrat sur la ligne la plus recente\n",
    "                - creer une nouvelle ligne contrat avec id_equip, id_joueur, date_debut_contrat\n",
    "- va falloir trier les joueuers qui n'ont pas joué avant de les basculer dans les stats joueur (attribut dnp)\n",
    "- va falloir trouver les joueurs non contenus dans la base des joueurs et les ajouter (nom à minima)\n",
    "- va falloir gérer les blessures  : \n",
    "> - les ajouter à la table blessure si elle ne sont pas déjà dedans\n",
    "> - noter comme apte les joueurs présents dans la table blessure, dont la date de guérison n'est pas connue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dossierBase=r'C:\\Users\\martin.schoreisz\\git\\Basket\\Basket\\data\\testUsa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-22\n",
      "2 None\n",
      "2\n",
      "2 None\n",
      "3\n",
      "2020-12-23\n",
      "3 None\n",
      "4\n",
      "4 None\n",
      "5\n",
      "5 None\n",
      "6\n",
      "6 None\n",
      "7\n",
      "7 None\n",
      "8\n",
      "8 None\n",
      "9\n",
      "9 None\n",
      "10\n",
      "10 None\n",
      "11\n",
      "11 None\n",
      "12\n",
      "12 None\n",
      "13\n",
      "13 None\n",
      "14\n",
      "14 None\n",
      "15\n",
      "2020-12-25\n",
      "15 None\n",
      "16\n",
      "16 None\n",
      "17\n",
      "17 None\n",
      "18\n",
      "18 None\n",
      "19\n",
      "19 None\n",
      "20\n",
      "2020-12-26\n",
      "20 None\n",
      "21\n",
      "21 None\n",
      "22\n",
      "22 None\n",
      "23\n",
      "23 None\n",
      "24\n",
      "24 None\n",
      "25\n",
      "25 None\n",
      "26\n",
      "26 None\n",
      "27\n",
      "27 None\n",
      "28\n",
      "28 None\n",
      "29\n",
      "29 None\n",
      "30\n",
      "2020-12-27\n",
      "30 None\n",
      "31\n",
      "31 None\n",
      "32\n",
      "32 None\n",
      "33\n",
      "33 None\n",
      "34\n",
      "34 None\n",
      "35\n",
      "35 None\n",
      "36\n",
      "36 None\n",
      "37\n",
      "37 None\n",
      "38\n",
      "38 None\n",
      "39\n",
      "39 None\n",
      "40\n",
      "2020-12-28\n",
      "40 None\n",
      "41\n",
      "41 None\n",
      "42\n",
      "42 None\n",
      "43\n",
      "43 None\n",
      "44\n",
      "44 None\n",
      "45\n",
      "2020-12-29\n",
      "45 None\n",
      "46\n",
      "46 None\n",
      "47\n",
      "47 None\n",
      "48\n",
      "48 None\n",
      "49\n",
      "49 None\n",
      "50\n",
      "50 None\n",
      "51\n",
      "51 None\n",
      "52\n",
      "52 None\n",
      "53\n",
      "53 None\n",
      "54\n",
      "54 None\n",
      "55\n",
      "2020-12-30\n",
      "55 None\n",
      "56\n",
      "56 None\n",
      "57\n",
      "57 None\n",
      "58\n",
      "58 None\n",
      "59\n",
      "59 None\n",
      "60\n",
      "60 None\n",
      "61\n",
      "2020-12-31\n",
      "61 None\n",
      "62\n",
      "62 None\n",
      "63\n",
      "63 None\n",
      "64\n",
      "64 None\n",
      "65\n",
      "65 None\n",
      "66\n",
      "66 None\n",
      "67\n",
      "67 None\n",
      "68\n",
      "2021-01-01\n",
      "68 None\n",
      "69\n",
      "69 None\n",
      "70\n",
      "70 None\n",
      "71\n",
      "71 None\n",
      "72\n",
      "72 None\n",
      "73\n",
      "73 None\n",
      "74\n",
      "74 None\n",
      "75\n",
      "75 None\n",
      "76\n",
      "76 None\n",
      "77\n",
      "77 None\n",
      "78\n",
      "2021-01-02\n",
      "78 None\n",
      "79\n",
      "79 None\n",
      "80\n",
      "80 None\n",
      "81\n",
      "81 None\n",
      "82\n",
      "82 None\n",
      "83\n",
      "83 None\n",
      "84\n",
      "2021-01-03\n",
      "84 None\n",
      "85\n",
      "85 None\n",
      "86\n",
      "86 None\n",
      "87\n",
      "87 None\n",
      "88\n",
      "88 None\n",
      "89\n",
      "89 None\n",
      "90\n",
      "90 None\n",
      "91\n",
      "91 None\n",
      "92\n",
      "2021-01-04\n",
      "92 None\n",
      "93\n",
      "93 None\n",
      "94\n",
      "94 None\n",
      "95\n",
      "95 None\n",
      "96\n",
      "96 None\n",
      "97\n",
      "97 None\n",
      "98\n",
      "98 None\n",
      "99\n",
      "99 None\n",
      "100\n",
      "100 None\n",
      "101\n",
      "2021-01-05\n",
      "101 None\n",
      "102\n",
      "102 None\n",
      "103\n",
      "103 None\n",
      "104\n",
      "104 None\n",
      "105\n",
      "105 None\n",
      "106\n",
      "2021-01-06\n",
      "106 None\n",
      "107\n",
      "107 None\n",
      "108\n",
      "108 None\n",
      "109\n",
      "109 None\n",
      "110\n",
      "110 None\n",
      "111\n",
      "111 None\n",
      "112\n",
      "112 None\n",
      "113\n",
      "113 None\n",
      "114\n",
      "114 None\n",
      "115\n",
      "115 None\n",
      "116\n",
      "116 None\n",
      "117\n",
      "2021-01-07\n",
      "117 None\n",
      "118\n",
      "118 None\n",
      "119\n",
      "119 None\n",
      "120\n",
      "120 None\n",
      "121\n",
      "121 None\n",
      "122\n",
      "2021-01-08\n",
      "122 None\n",
      "123\n",
      "123 None\n",
      "124\n",
      "124 None\n",
      "125\n",
      "125 None\n",
      "126\n",
      "126 None\n",
      "127\n",
      "127 None\n",
      "128\n",
      "128 None\n",
      "129\n",
      "129 None\n",
      "130\n",
      "130 None\n",
      "131\n",
      "131 None\n",
      "132\n",
      "2021-01-09\n",
      "132 None\n",
      "133\n",
      "133 None\n",
      "134\n",
      "134 None\n",
      "135\n",
      "135 None\n",
      "136\n",
      "136 None\n",
      "137\n",
      "137 None\n",
      "138\n",
      "138 None\n",
      "139\n",
      "139 None\n",
      "140\n",
      "2021-01-10\n",
      "140 None\n",
      "141\n",
      "141 None\n",
      "142\n",
      "142 None\n",
      "143\n",
      "143 None\n",
      "144\n",
      "144 None\n",
      "145\n",
      "145 None\n",
      "146\n",
      "146 None\n",
      "147\n",
      "2021-01-11\n",
      "147 None\n",
      "148\n",
      "148 None\n",
      "149\n",
      "149 None\n",
      "150\n",
      "150 None\n",
      "151\n",
      "151 None\n",
      "152\n",
      "152 None\n",
      "153\n",
      "153 None\n",
      "154\n",
      "2021-01-12\n",
      "154 None\n",
      "155\n",
      "155 None\n",
      "156\n",
      "156 None\n",
      "157\n",
      "157 None\n",
      "158\n",
      "158 None\n",
      "159\n",
      "159 None\n",
      "160\n",
      "2021-01-13\n",
      "160 None\n",
      "161\n",
      "161 None\n",
      "162\n",
      "162 None\n",
      "163\n",
      "163 None\n",
      "164\n",
      "164 None\n",
      "165\n",
      "165 None\n",
      "166\n",
      "166 None\n",
      "167\n",
      "2021-01-14\n",
      "167 None\n",
      "168\n",
      "168 None\n",
      "169\n",
      "169 None\n",
      "170\n",
      "170 None\n",
      "171\n",
      "171 None\n",
      "172\n",
      "2021-01-15\n",
      "172 None\n",
      "173\n",
      "173 None\n",
      "174\n",
      "174 None\n",
      "175\n",
      "175 None\n",
      "176\n",
      "176 None\n",
      "177\n",
      "177 None\n",
      "178\n",
      "178 None\n",
      "179\n",
      "2021-01-16\n",
      "179 None\n",
      "180\n",
      "180 None\n",
      "181\n",
      "181 None\n",
      "182\n",
      "182 None\n",
      "183\n",
      "183 None\n",
      "184\n",
      "184 None\n",
      "185\n",
      "2021-01-17\n",
      "185 None\n",
      "186\n",
      "186 None\n",
      "187\n",
      "187 None\n",
      "188\n",
      "188 None\n",
      "189\n",
      "189 None\n",
      "190\n",
      "2021-01-18\n",
      "190 None\n",
      "191\n",
      "191 None\n",
      "192\n",
      "192 None\n",
      "193\n",
      "193 None\n",
      "194\n",
      "194 None\n",
      "195\n",
      "195 None\n",
      "196\n",
      "196 None\n",
      "197\n",
      "197 None\n",
      "198\n",
      "198 None\n",
      "199\n",
      "2021-01-19\n",
      "199 None\n",
      "200\n",
      "200 None\n",
      "201\n",
      "2021-01-20\n",
      "201 None\n",
      "202\n",
      "202 None\n",
      "203\n",
      "203 None\n",
      "204\n",
      "204 None\n",
      "205\n",
      "205 None\n",
      "206\n",
      "206 None\n",
      "207\n",
      "207 None\n",
      "208\n",
      "208 None\n",
      "209\n",
      "209 None\n",
      "210\n",
      "2021-01-21\n",
      "210 None\n",
      "211\n",
      "211 None\n",
      "212\n",
      "212 None\n",
      "213\n",
      "2021-01-22\n",
      "213 None\n",
      "214\n",
      "214 None\n",
      "215\n",
      "215 None\n",
      "216\n",
      "216 None\n",
      "217\n",
      "217 None\n",
      "218\n",
      "218 None\n",
      "219\n",
      "219 None\n",
      "220\n",
      "220 None\n",
      "221\n",
      "221 None\n",
      "222\n",
      "222 None\n",
      "223\n",
      "223 None\n",
      "224\n",
      "2021-01-23\n",
      "224 None\n",
      "225\n",
      "225 None\n",
      "226\n",
      "226 None\n",
      "227\n",
      "227 None\n",
      "228\n",
      "228 None\n",
      "229\n",
      "229 None\n",
      "230\n",
      "230 None\n",
      "231\n"
     ]
    }
   ],
   "source": [
    "with ct.ConnexionBdd('basket','maison') as c:\n",
    "    with os.scandir(dossierBase) as it : \n",
    "        for entry in it:\n",
    "            #paramètres généraux par date\n",
    "            date=entry.name\n",
    "            id_type_match=0\n",
    "            id_saison=1\n",
    "            root=os.path.join(dossierBase,date)\n",
    "            \n",
    "            #recuperer les données de joueurs, blesses et les contrat avant la journee\n",
    "            dfJoueursBdd=pd.read_sql('select id_joueur, nom_simple from donnees_source.joueur',c.sqlAlchemyConn)\n",
    "            dfContratBdd=pd.read_sql(\"SELECT * FROM donnees_source.contrat WHERE date_fin_contrat IS null\",c.sqlAlchemyConn)\n",
    "            dfJoueursBlessesBdd=pd.read_sql(\"select * from donnees_source.blessure WHERE date_guerison IS NULL\",c.sqlAlchemyConn)\n",
    "            print(date)\n",
    "            \n",
    "            for f in [entry.name for entry in os.scandir(root) if entry.is_file() and 'equipe' not in entry.name and entry.name.endswith('.csv')] :\n",
    "                \n",
    "                #recuperer l'identifiant du match dans le dossier contenant les fichiers\n",
    "                groupe=f.split('_')[0][1:]\n",
    "                \n",
    "                \n",
    "                #lire le fichier csv du match, transformer pour remplir la table des matchs\n",
    "                dfMatchCsv=pd.read_csv(root+os.sep+f).rename(columns={'equipe':'id_equipe'})\n",
    "                equipeExt=dfMatchCsv.iloc[0].id_equipe\n",
    "                equipeDom=dfMatchCsv.iloc[1].id_equipe\n",
    "                pd.DataFrame({'id_saison':[id_saison],\n",
    "                                      'date_match':[date], \n",
    "                                      'equipe_domicile':[equipeDom], \n",
    "                                      'equipe_exterieure':[equipeExt],\n",
    "                                      'id_type_match':[id_type_match]}).to_sql('match', c.sqlAlchemyConn, schema='donnees_source', if_exists='append', index=False)\n",
    "                print(idMatchBdd)\n",
    "                \n",
    "                #recuperer l'id_match : \n",
    "                idMatchBdd=c.sqlAlchemyConn.execute(\"SELECT last_value FROM donnees_source.match_id_match_seq\").fetchone()[0] \n",
    "                print(idMatchBdd)\n",
    "                \n",
    "                #melt la table csv pour remplir la table des scores de match\n",
    "                dfScoreMatch=dfMatchCsv.melt(id_vars=['id_equipe'], value_vars=['q1','q2','q3','q4','final'],\n",
    "                            var_name='id_periode', value_name='score_periode').sort_values('id_equipe')\n",
    "                dfScoreMatch['id_match']=idMatchBdd\n",
    "                dfScoreMatch.to_sql('score_match', c.sqlAlchemyConn, schema='donnees_source', if_exists='append', index=False)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \"\"\"#maintenant il faut lire les fichiers stats_equipe associés\n",
    "                for i in (0,1) : \n",
    "                    nomFichierEquipe=f'm{groupe}_equipe{i}_{date}.csv'\n",
    "                    dfStatsJoueursCsv=pd.read_csv(os.path.join(root,nomFichierEquipe))\n",
    "                    idEquipe=dfMatchCsv.loc[i].id_equipe\n",
    "                    \n",
    "                    \n",
    "                    #pensez à enlever du fichier source les joueurs n'ayant pas joué et non blesse avant de creer la df des statsJoueur: \n",
    "                    dfStatsJoueursActifCsv=dfStatsJoueursCsv.loc[(~dfStatsJoueursCsv['dnp']) | dfStatsJoueursCsv['blesse']]\n",
    "                    \n",
    "                    #JoueurActifs\n",
    "                    #le pb ça va etre de recuperer les id_joueurs, va falloir telecharger d'abords la table de correspondance\n",
    "                    #faire la jointure en amont et ensuite on bascule tout le monde\n",
    "                    dfJoueursTot=dfStatsJoueursActifCsv.merge(dfJoueursBdd, on='nom_simple', how='left')                \n",
    "\n",
    "                    #pensez à checker si tous les joueurs sont présents dans la base joueur, et les ajouter si ils n'y sont pas\n",
    "                    dfJoueurInconnus=dfJoueursTot.loc[dfJoueursTot.id_joueur.isna()]\n",
    "                    if not dfJoueurInconnus.empty : \n",
    "                        dfJoueurInconnus=dfJoueurInconnus[['nom','nom_simple']]\n",
    "                        #basculer dans Bdd\n",
    "                        #dfJoueurInconnus.to_sql('joueur', c.sqlAlchemyConn, schema='donnees_source', if_exists='append', index=False)\n",
    "                        print(f'nouveau joueur : {dfJoueurInconnus.nom.tolist()} equipe {i}')\n",
    "                    #refaire un import et jointure au cas où des joueurs aient été ajoutés dans table joueurs, idem pour les contrats\n",
    "                    dfJoueursBdd=pd.read_sql('select id_joueur, nom_simple from donnees_source.joueur',c.sqlAlchemyConn)\n",
    "                    dfJoueursTot=dfStatsJoueursActifCsv.merge(dfJoueursBdd, on='nom_simple')\n",
    "                    \n",
    "                    \n",
    "                    #contrat : \n",
    "                    #1.verifier si id_joueur dans la base contrat : \n",
    "                    dfJoueurSansContrat=dfJoueursTot.loc[~dfJoueursTot.id_joueur.isin(dfContratBdd.id_joueur.tolist())]\n",
    "                    if not dfJoueurSansContrat.empty : #joueur sans contrat\n",
    "                        dfNewContrat=pd.DataFrame({'id_joueur':dfJoueurSansContrat.id_joueur.tolist(),'id_equipe':idEquipe,'date_debut_contrat':date})\n",
    "                        #dfNewContrat.to_sql('contrat',c.sqlAlchemyConn, schema='donnees_source', if_exists='append', index=False)\n",
    "                    #joueur avec contrat : \n",
    "                    #jointure entre la table contratBdd et celle du match sur id_joueur pour comparer les equipes\n",
    "                    if not dfContratBdd.empty : \n",
    "                        dfContratJoueurMatch=dfContratBdd.merge(dfJoueursTot[['id_joueur']], on='id_joueur')\n",
    "                        dfContratJoueurChange=dfContratJoueurMatch.loc[dfContratJoueurMatch.id_equipe!=idEquipe]\n",
    "                        if not dfContratJoueurChange.empty: #si un joueur a changé d'équipe\n",
    "                            dateFinContrat=(pd.to_datetime(date)-pd.Timedelta(1,'day')).strftime('%Y-%m-%d')\n",
    "                            print(dfContratJoueurChange.id_joueur, dateFinContrat)\n",
    "                            #il faut update la table avec la valeur de date en date_fin_contrat\n",
    "                            #c.sqlAlchemyConn.execute(f\"UPDATE donnees_source.contrat SET date_fin_contrat = '{dateFinContrat}' WHERE id_contrat=any(array{dfContratJoueurChange.id_contrat.tolist()})\")\n",
    "                            #et inserer de nouvelle lignes\n",
    "                            pd.DataFrame({'id_joueur':dfContratJoueurChange.id_joueur.tolist(),'id_equipe':idEquipe,'date_debut_contrat':date}).to_sql('contrat',c.sqlAlchemyConn, schema='donnees_source', if_exists='append', index=False)\n",
    "                            \n",
    "                    \n",
    "                    #Blessure\n",
    "                    #checker si des joueurs sont notés blessé et ne sont pas déjà dans la base blessure\n",
    "                    dfJoueursBlesses=dfJoueursTot.loc[dfJoueursTot['blesse']]\n",
    "                    if not dfJoueursBlesses.empty : #si des joueurs blesses, verifier qu'ils ne sont pas déjà presents dans la base\n",
    "                        dfNouveauBlesse=dfJoueursBlesses.loc[~dfJoueursBlesses.id_joueur.isin(dfJoueursBlessesBdd.id_joueur.tolist())]\n",
    "                        if not dfNouveauBlesse.empty : \n",
    "                            dfJoueursBlesses=dfJoueursBlesses.loc[~dfJoueursBlesses.id_joueur.isin(dfJoueursBlessesBdd.id_joueur.tolist())].copy()\n",
    "                            #dfNouveauBlesse[['id_joueur']].assign(date_blessure=date, id_type_blessure=99).to_sql('blessure', c.sqlAlchemyConn, schema='donnees_source', if_exists='append', index=False)\n",
    "                            print(f'blesse : {dfNouveauBlesse.nom.tolist()}')        \n",
    "                    #checker si des joueurs ayant joué étaient noté blessé mais sont revenus\n",
    "                    dfJoueurRetourBlessure=dfJoueursTot.loc[(dfJoueursTot.id_joueur.isin(dfJoueursBlessesBdd.id_joueur.tolist())) & (~dfJoueursTot['blesse'])]\n",
    "                    if not dfJoueurRetourBlessure.empty : #si des retours\n",
    "                        dateGuerison=(pd.to_datetime(date)-pd.Timedelta(1,'day')).strftime('%Y-%m-%d')\n",
    "                        #il faut update la table avec la valeur de date en date_fin_blessurre\n",
    "                        #c.sqlAlchemyConn.execute(f\"UPDATE donnees_source.blessure SET date_guerison = '{dateGuerison}' WHERE id_joueur=any(array{dfJoueurRetourBlessure.id_joueur.tolist()}) AND date_guerison is null\")\n",
    "                        print(f'retour blessure : {dfJoueurRetourBlessure.nom.tolist()}')\n",
    "\n",
    "                    #ensuite mettre en forme les stats de joueurs\n",
    "                    dfStatsJoueursBdd=dfJoueursTot.loc[~dfJoueursTot['dnp'][['minute', 'points', 'rebonds', 'passes_dec', 'steal',\n",
    "                       'contres', 'tir_reussi', 'tir_tentes', 'pct_tir', 'trois_pt_r',\n",
    "                       'trois_pt_t', 'pct_3_pt', 'lanc_frc_r', 'lanc_frc_t', 'pct_lfrc',\n",
    "                       'rebonds_o', 'rebonds_d', 'ball_perdu', 'faute_p', 'plus_moins','score_ttfl', 'id_joueur']].copy()\n",
    "                    dfStatsJoueursBdd['id_match']=idMatchBdd\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_equipe</th>\n",
       "      <th>id_periode</th>\n",
       "      <th>score_periode</th>\n",
       "      <th>id_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BKN</td>\n",
       "      <td>q1</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BKN</td>\n",
       "      <td>q2</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BKN</td>\n",
       "      <td>q3</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BKN</td>\n",
       "      <td>q4</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BKN</td>\n",
       "      <td>final</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GSW</td>\n",
       "      <td>q1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GSW</td>\n",
       "      <td>q2</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GSW</td>\n",
       "      <td>q3</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GSW</td>\n",
       "      <td>q4</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GSW</td>\n",
       "      <td>final</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_equipe id_periode  score_periode  id_match\n",
       "1       BKN         q1             40         1\n",
       "3       BKN         q2             23         1\n",
       "5       BKN         q3             36         1\n",
       "7       BKN         q4             26         1\n",
       "9       BKN      final            125         1\n",
       "0       GSW         q1             25         1\n",
       "2       GSW         q2             20         1\n",
       "4       GSW         q3             26         1\n",
       "6       GSW         q4             28         1\n",
       "8       GSW      final             99         1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfScoreMatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m0_2020-12-22.csv\n",
      "2020-12-22 ; GSW\n",
      "m1_2020-12-22.csv\n",
      "2020-12-22 ; LAC\n",
      "m0_2020-12-23.csv\n",
      "2020-12-23 ; CHA\n",
      "m10_2020-12-23.csv\n",
      "2020-12-23 ; UTA\n",
      "m11_2020-12-23.csv\n",
      "2020-12-23 ; DAL\n",
      "m1_2020-12-23.csv\n",
      "2020-12-23 ; NYK\n",
      "m2_2020-12-23.csv\n",
      "2020-12-23 ; MIA\n",
      "m3_2020-12-23.csv\n",
      "2020-12-23 ; WAS\n",
      "m4_2020-12-23.csv\n",
      "2020-12-23 ; MIL\n",
      "m5_2020-12-23.csv\n",
      "2020-12-23 ; NOP\n",
      "m6_2020-12-23.csv\n",
      "2020-12-23 ; ATL\n",
      "m7_2020-12-23.csv\n",
      "2020-12-23 ; SAS\n",
      "m8_2020-12-23.csv\n",
      "2020-12-23 ; DET\n",
      "m9_2020-12-23.csv\n",
      "2020-12-23 ; SAC\n",
      "m0_2020-12-25.csv\n",
      "2020-12-25 ; NOP\n",
      "m1_2020-12-25.csv\n",
      "2020-12-25 ; GSW\n",
      "m2_2020-12-25.csv\n",
      "2020-12-25 ; BKN\n",
      "m3_2020-12-25.csv\n",
      "2020-12-25 ; DAL\n",
      "m4_2020-12-25.csv\n",
      "2020-12-25 ; LAC\n",
      "m0_2020-12-26.csv\n",
      "2020-12-26 ; ATL\n",
      "m1_2020-12-26.csv\n",
      "2020-12-26 ; OKC\n",
      "m2_2020-12-26.csv\n",
      "2020-12-26 ; CLE\n",
      "m3_2020-12-26.csv\n",
      "2020-12-26 ; ORL\n",
      "m4_2020-12-26.csv\n",
      "2020-12-26 ; PHI\n",
      "m5_2020-12-26.csv\n",
      "2020-12-26 ; IND\n",
      "m6_2020-12-26.csv\n",
      "2020-12-26 ; TOR\n",
      "m7_2020-12-26.csv\n",
      "2020-12-26 ; MIN\n",
      "m8_2020-12-26.csv\n",
      "2020-12-26 ; HOU\n",
      "m9_2020-12-26.csv\n",
      "2020-12-26 ; PHX\n",
      "m0_2020-12-27.csv\n",
      "2020-12-27 ; DAL\n",
      "m1_2020-12-27.csv\n",
      "2020-12-27 ; BKN\n",
      "m2_2020-12-27.csv\n",
      "2020-12-27 ; ORL\n",
      "m3_2020-12-27.csv\n",
      "2020-12-27 ; SAS\n",
      "m4_2020-12-27.csv\n",
      "2020-12-27 ; PHI\n",
      "m5_2020-12-27.csv\n",
      "2020-12-27 ; MIL\n",
      "m6_2020-12-27.csv\n",
      "2020-12-27 ; BOS\n",
      "m7_2020-12-27.csv\n",
      "2020-12-27 ; GSW\n",
      "m8_2020-12-27.csv\n",
      "2020-12-27 ; PHX\n",
      "m9_2020-12-27.csv\n",
      "2020-12-27 ; MIN\n",
      "m0_2020-12-28.csv\n",
      "2020-12-28 ; DET\n",
      "m1_2020-12-28.csv\n",
      "2020-12-28 ; MEM\n",
      "m2_2020-12-28.csv\n",
      "2020-12-28 ; UTA\n",
      "m3_2020-12-28.csv\n",
      "2020-12-28 ; HOU\n",
      "m4_2020-12-28.csv\n",
      "2020-12-28 ; POR\n",
      "m0_2020-12-29.csv\n",
      "2020-12-29 ; NYK\n",
      "m1_2020-12-29.csv\n",
      "2020-12-29 ; GSW\n",
      "m2_2020-12-29.csv\n",
      "2020-12-29 ; BOS\n",
      "m3_2020-12-29.csv\n",
      "2020-12-29 ; TOR\n",
      "m4_2020-12-29.csv\n",
      "2020-12-29 ; CHI\n",
      "m5_2020-12-29.csv\n",
      "2020-12-29 ; MIL\n",
      "m6_2020-12-29.csv\n",
      "2020-12-29 ; ORL\n",
      "m7_2020-12-29.csv\n",
      "2020-12-29 ; NOP\n",
      "m8_2020-12-29.csv\n",
      "2020-12-29 ; MIN\n",
      "m9_2020-12-29.csv\n",
      "2020-12-29 ; DEN\n",
      "m0_2020-12-30.csv\n",
      "2020-12-30 ; MEM\n",
      "m1_2020-12-30.csv\n",
      "2020-12-30 ; ATL\n",
      "m2_2020-12-30.csv\n",
      "2020-12-30 ; MIL\n",
      "m3_2020-12-30.csv\n",
      "2020-12-30 ; CHA\n",
      "m4_2020-12-30.csv\n",
      "2020-12-30 ; LAL\n",
      "m5_2020-12-30.csv\n",
      "2020-12-30 ; POR\n",
      "m0_2020-12-31.csv\n",
      "2020-12-31 ; CLE\n",
      "m1_2020-12-31.csv\n",
      "2020-12-31 ; CHI\n",
      "m2_2020-12-31.csv\n",
      "2020-12-31 ; PHI\n",
      "m3_2020-12-31.csv\n",
      "2020-12-31 ; SAC\n",
      "m4_2020-12-31.csv\n",
      "2020-12-31 ; NYK\n",
      "m5_2020-12-31.csv\n",
      "2020-12-31 ; NOP\n",
      "m6_2020-12-31.csv\n",
      "2020-12-31 ; PHX\n",
      "m0_2021-01-01.csv\n",
      "2021-01-01 ; MEM\n",
      "m1_2021-01-01.csv\n",
      "2021-01-01 ; BOS\n",
      "m2_2021-01-01.csv\n",
      "2021-01-01 ; MIA\n",
      "m3_2021-01-01.csv\n",
      "2021-01-01 ; ATL\n",
      "m4_2021-01-01.csv\n",
      "2021-01-01 ; CHI\n",
      "m5_2021-01-01.csv\n",
      "2021-01-01 ; WAS\n",
      "m6_2021-01-01.csv\n",
      "2021-01-01 ; LAL\n",
      "m7_2021-01-01.csv\n",
      "2021-01-01 ; PHX\n",
      "m8_2021-01-01.csv\n",
      "2021-01-01 ; LAC\n",
      "m9_2021-01-01.csv\n",
      "2021-01-01 ; POR\n",
      "m0_2021-01-02.csv\n",
      "2021-01-02 ; SAC\n",
      "m1_2021-01-02.csv\n",
      "2021-01-02 ; NYK\n",
      "m2_2021-01-02.csv\n",
      "2021-01-02 ; OKC\n",
      "m3_2021-01-02.csv\n",
      "2021-01-02 ; CHA\n",
      "m4_2021-01-02.csv\n",
      "2021-01-02 ; CLE\n",
      "m5_2021-01-02.csv\n",
      "2021-01-02 ; TOR\n",
      "m0_2021-01-03.csv\n",
      "2021-01-03 ; BOS\n",
      "m1_2021-01-03.csv\n",
      "2021-01-03 ; WAS\n",
      "m2_2021-01-03.csv\n",
      "2021-01-03 ; LAL\n",
      "m3_2021-01-03.csv\n",
      "2021-01-03 ; DEN\n",
      "m4_2021-01-03.csv\n",
      "2021-01-03 ; UTA\n",
      "m5_2021-01-03.csv\n",
      "2021-01-03 ; DAL\n",
      "m6_2021-01-03.csv\n",
      "2021-01-03 ; LAC\n",
      "m7_2021-01-03.csv\n",
      "2021-01-03 ; POR\n",
      "m0_2021-01-04.csv\n",
      "2021-01-04 ; CLE\n",
      "m1_2021-01-04.csv\n",
      "2021-01-04 ; CHA\n",
      "m2_2021-01-04.csv\n",
      "2021-01-04 ; NYK\n",
      "m3_2021-01-04.csv\n",
      "2021-01-04 ; OKC\n",
      "m4_2021-01-04.csv\n",
      "2021-01-04 ; BOS\n",
      "m5_2021-01-04.csv\n",
      "2021-01-04 ; DAL\n",
      "m6_2021-01-04.csv\n",
      "2021-01-04 ; DET\n",
      "m7_2021-01-04.csv\n",
      "2021-01-04 ; IND\n",
      "m8_2021-01-04.csv\n",
      "2021-01-04 ; SAC\n",
      "m0_2021-01-05.csv\n",
      "2021-01-05 ; UTA\n",
      "m1_2021-01-05.csv\n",
      "2021-01-05 ; LAL\n",
      "m2_2021-01-05.csv\n",
      "2021-01-05 ; MIN\n",
      "m3_2021-01-05.csv\n",
      "2021-01-05 ; SAS\n",
      "m4_2021-01-05.csv\n",
      "2021-01-05 ; CHI\n",
      "m0_2021-01-06.csv\n",
      "2021-01-06 ; HOU\n",
      "m10_2021-01-06.csv\n",
      "2021-01-06 ; CHI\n",
      "m1_2021-01-06.csv\n",
      "2021-01-06 ; CLE\n",
      "m2_2021-01-06.csv\n",
      "2021-01-06 ; WAS\n",
      "m3_2021-01-06.csv\n",
      "2021-01-06 ; CHA\n",
      "m4_2021-01-06.csv\n",
      "2021-01-06 ; BOS\n",
      "m5_2021-01-06.csv\n",
      "2021-01-06 ; UTA\n",
      "m6_2021-01-06.csv\n",
      "2021-01-06 ; DET\n",
      "m7_2021-01-06.csv\n",
      "2021-01-06 ; OKC\n",
      "m8_2021-01-06.csv\n",
      "2021-01-06 ; TOR\n",
      "m9_2021-01-06.csv\n",
      "2021-01-06 ; LAC\n",
      "m0_2021-01-07.csv\n",
      "2021-01-07 ; PHI\n",
      "m1_2021-01-07.csv\n",
      "2021-01-07 ; CLE\n",
      "m2_2021-01-07.csv\n",
      "2021-01-07 ; DAL\n",
      "m3_2021-01-07.csv\n",
      "2021-01-07 ; SAS\n",
      "m4_2021-01-07.csv\n",
      "2021-01-07 ; MIN\n",
      "m0_2021-01-08.csv\n",
      "2021-01-08 ; PHX\n",
      "m1_2021-01-08.csv\n",
      "2021-01-08 ; WAS\n",
      "m2_2021-01-08.csv\n",
      "2021-01-08 ; OKC\n",
      "m3_2021-01-08.csv\n",
      "2021-01-08 ; CHA\n",
      "m4_2021-01-08.csv\n",
      "2021-01-08 ; ORL\n",
      "m5_2021-01-08.csv\n",
      "2021-01-08 ; BKN\n",
      "m6_2021-01-08.csv\n",
      "2021-01-08 ; UTA\n",
      "m7_2021-01-08.csv\n",
      "2021-01-08 ; LAC\n",
      "m8_2021-01-08.csv\n",
      "2021-01-08 ; CHI\n",
      "m9_2021-01-08.csv\n",
      "2021-01-08 ; TOR\n",
      "m0_2021-01-09.csv\n",
      "2021-01-09 ; DEN\n",
      "m1_2021-01-09.csv\n",
      "2021-01-09 ; ATL\n",
      "m2_2021-01-09.csv\n",
      "2021-01-09 ; PHX\n",
      "m3_2021-01-09.csv\n",
      "2021-01-09 ; MIA\n",
      "m4_2021-01-09.csv\n",
      "2021-01-09 ; CLE\n",
      "m5_2021-01-09.csv\n",
      "2021-01-09 ; SAS\n",
      "m6_2021-01-09.csv\n",
      "2021-01-09 ; ORL\n",
      "m7_2021-01-09.csv\n",
      "2021-01-09 ; POR\n",
      "m0_2021-01-10.csv\n",
      "2021-01-10 ; UTA\n",
      "m1_2021-01-10.csv\n",
      "2021-01-10 ; CHI\n",
      "m2_2021-01-10.csv\n",
      "2021-01-10 ; OKC\n",
      "m3_2021-01-10.csv\n",
      "2021-01-10 ; DEN\n",
      "m4_2021-01-10.csv\n",
      "2021-01-10 ; LAL\n",
      "m5_2021-01-10.csv\n",
      "2021-01-10 ; SAS\n",
      "m6_2021-01-10.csv\n",
      "2021-01-10 ; TOR\n",
      "m0_2021-01-11.csv\n",
      "2021-01-11 ; NYK\n",
      "m1_2021-01-11.csv\n",
      "2021-01-11 ; MEM\n",
      "m2_2021-01-11.csv\n",
      "2021-01-11 ; MIL\n",
      "m3_2021-01-11.csv\n",
      "2021-01-11 ; PHX\n",
      "m4_2021-01-11.csv\n",
      "2021-01-11 ; PHI\n",
      "m5_2021-01-11.csv\n",
      "2021-01-11 ; TOR\n",
      "m6_2021-01-11.csv\n",
      "2021-01-11 ; IND\n",
      "m0_2021-01-12.csv\n",
      "2021-01-12 ; MIA\n",
      "m1_2021-01-12.csv\n",
      "2021-01-12 ; DEN\n",
      "m2_2021-01-12.csv\n",
      "2021-01-12 ; UTA\n",
      "m3_2021-01-12.csv\n",
      "2021-01-12 ; LAL\n",
      "m4_2021-01-12.csv\n",
      "2021-01-12 ; SAS\n",
      "m5_2021-01-12.csv\n",
      "2021-01-12 ; IND\n",
      "m0_2021-01-13.csv\n",
      "2021-01-13 ; DAL\n",
      "m1_2021-01-13.csv\n",
      "2021-01-13 ; MIL\n",
      "m2_2021-01-13.csv\n",
      "2021-01-13 ; BKN\n",
      "m3_2021-01-13.csv\n",
      "2021-01-13 ; MEM\n",
      "m4_2021-01-13.csv\n",
      "2021-01-13 ; LAL\n",
      "m5_2021-01-13.csv\n",
      "2021-01-13 ; NOP\n",
      "m6_2021-01-13.csv\n",
      "2021-01-13 ; POR\n",
      "m0_2021-01-14.csv\n",
      "2021-01-14 ; MIA\n",
      "m1_2021-01-14.csv\n",
      "2021-01-14 ; CHA\n",
      "m2_2021-01-14.csv\n",
      "2021-01-14 ; HOU\n",
      "m3_2021-01-14.csv\n",
      "2021-01-14 ; GSW\n",
      "m4_2021-01-14.csv\n",
      "2021-01-14 ; IND\n"
     ]
    }
   ],
   "source": [
    "    for root, dossier, files in os.walk(dossierBase) : \n",
    "        for f in files :\n",
    "            id_type_match=0\n",
    "            id_saison=1\n",
    "            if 'equipe' in f and f.endswith('.csv'): \n",
    "                continue\n",
    "            elif 'equipe' not in f and f.endswith('.csv'):\n",
    "                #recuperer l'id_match : \n",
    "                idMatch=c.sqlAlchemyConn.execute(\"SELECT last_value FROM donnees_source.match_id_match_seq\").fetchone()[0] \n",
    "                #recuperer l'identifiant du match dans le dossier contenant les fichiers\n",
    "                groupe=f.split('_')[0][1:]\n",
    "                #recuperer la date du match\n",
    "                date=f.split('_')[1][:-4]\n",
    "                print(f)\n",
    "                #lire le fichier csv du match, transformer pour remplir la table des matchs\n",
    "                dfMatchCsv=pd.read_csv(os.path.join(root,f)).rename(columns={'equipe':'id_equipe'})\n",
    "                equipeExt=dfMatchCsv.iloc[0].id_equipe\n",
    "                equipeDom=dfMatchCsv.iloc[1].id_equipe\n",
    "                dfMatchBdd=pd.DataFrame({'id_saison':[id_saison],\n",
    "                                      'date_match':[date], \n",
    "                                      'equipe_domicile':[equipeDom], \n",
    "                                      'equipe_exterieure':[equipeExt],\n",
    "                                      'id_type_match':[id_type_match],\n",
    "                                        'id_match':idMatch})\n",
    "                #melt la table csv pour remplir la table des scores de match\n",
    "                dfScoreMatch=dfMatchCsv.melt(id_vars=['id_equipe'], value_vars=['q1','q2','q3','q4','final'],\n",
    "                            var_name='id_periode', value_name='score_periode').sort_values('id_equipe')\n",
    "                dfScoreMatch['id_match']=idMatch\n",
    "                \n",
    "                #maintenant il faut lire les fichiers stats_equipe associés\n",
    "                for i in (0,1) : \n",
    "                    nomFichierEquipe=f'm{groupe}_equipe{i}_{date}.csv'\n",
    "                    dfStatsJoueursCsv=pd.read_csv(os.path.join(root,nomFichierEquipe))\n",
    "                    idEquipe=dfMatchCsv.loc[i].id_equipe\n",
    "                    print(f'{date} ; {idEquipe}')\n",
    "                    \n",
    "                    #pensez à enlever du fichier source les joueurs n'ayant pas joué avant de creer la df des statsJoueur: \n",
    "                    dfStatsJoueursActifCsv=dfStatsJoueursCsv.loc[~dfStatsJoueursCsv['dnp']]\n",
    "                    \n",
    "                    #le pb ça va etre de recuperer les id_joueurs, va falloir telecharger d'abords la table de correspondance\n",
    "                    #faire la jointure en amont et ensuite on bascule tout le monde\n",
    "                    dfJoueursBdd=pd.read_sql('select id_joueur, nom_simple from donnees_source.joueur',c.sqlAlchemyConn)\n",
    "                    dfJoueursTot=dfStatsJoueursActifCsv.merge(dfJoueursBdd, on='nom_simple', how='left')                \n",
    "\n",
    "                    #pensez à checker si tous les joueurs sont présents dans la base joueur, et les ajouter si ils n'y sont pas\n",
    "                    dfJoueurInconnus=dfJoueursTot.loc[dfJoueursTot.id_joueur.isna()]\n",
    "                    if not dfJoueurInconnus.empty : \n",
    "                        dfJoueurInconnus=dfJoueurInconnus[['nom']]\n",
    "                        #basculer dans Bdd\n",
    "                        #dfJoueurInconnus.to_sql('joueur', c.sqlAlchemyConn, schema='donnees_source', if_exists='append', index=False)\n",
    "                        print(f'nouveau joueur : {dfJoueurInconnus.nom.tolist()} equipe {i}')\n",
    "\n",
    "                    #refaire un import et jointure au cas où des joueurs aient été ajoutés dans table joueurs, idem pour les contrats\n",
    "                    dfJoueursBddFinal=pd.read_sql('select id_joueur, nom_simple from donnees_source.joueur',c.sqlAlchemyConn)\n",
    "                    dfJoueursTot=dfStatsJoueursActifCsv.merge(dfJoueursBddFinal, on='nom_simple')\n",
    "                    \n",
    "                    \n",
    "                    #contrat : \n",
    "                    #1.verifier si id_joueur dans la base contrat : \n",
    "                    dfJoueurSansContrat=dfJoueursTot.loc[~dfJoueursTot.id_joueur.isin(dfContratBdd.id_joueur.tolist())]\n",
    "                    if not dfJoueurSansContrat.empty : #joueur sans contrat\n",
    "                        dfNewContrat=pd.DataFrame({'id_joueur':dfJoueurSansContrat.id_joueur.tolist(),'id_equipe':idEquipe,'date_debut_contrat':date})\n",
    "                        dfNewContrat.to_sql('contrat',c.sqlAlchemyConn, schema='donnees_source', if_exists='append', index=False)\n",
    "                    #joueur avec contrat : \n",
    "                    #jointure entre la table contratBdd et celle du match sur id_joueur pour comparer les equipes\n",
    "                    \n",
    "                    \"\"\"if not dfContratBdd.empty : \n",
    "                        dfContratJoueurMatch=dfContratBdd.merge(dfJoueursTot[['id_joueur']], on='id_joueur')\n",
    "                        dfContratJoueurChange=dfContratJoueurMatch.loc[dfContratJoueurMatch.id_equipe!=idEquipe]\n",
    "                        if not dfContratJoueurChange.empty: #si un joueur a changé d'équipe\n",
    "                            dateFinContrat=pd.to_datetime(date)-pd.Timedelta(1,'day').strftime('%Y-%m-%d')\n",
    "                            #il faut update la table avec la valeur de date en date_fin_contrat\n",
    "                            c.sqlAlchemyConn.execute(f\"UPDATE donnees_source.contrat SET date_fin_contrat = {dateFinContrat} WHERE id_contrat in ({','.join(dfContratJoueurChange.id_contrat.tolist())})\")\n",
    "                            #et inserer de nouvelle lignes\n",
    "                            pd.DataFrame({'id_joueur':dfContratJoueurChange.id_joueur.tolist(),'id_equipe':idEquipe,'date_debut_contrat':date}).to_sql(\n",
    "                                      'contrat',c.sqlAlchemyConn, schema='donnees_source', if_exists='append', index=False)\"\"\"\n",
    "                            \n",
    "                    \n",
    "\n",
    "                    #checker si des joueurs sont notés blessé et ne sont pas déjà dans la base blessure\n",
    "                    dfJoueursBlesses=dfStatsJoueursCsv.loc[dfStatsJoueursCsv['blesse']]\n",
    "                    rqtBlessesEncours=\"\"\"select b.*,j.nom \n",
    "                                          from donnees_source.joueur j JOIN donnees_source.blessure b ON j.id_joueur=b.id_joueur \n",
    "                                          WHERE b.date_guerison IS NULL\"\"\"\n",
    "                    dfJoueursBlessesBdd=pd.read_sql(rqtBlessesEncours,c.sqlAlchemyConn)\n",
    "                    if not dfJoueursBlesses.empty : #si des joueurs blesses, verifier qu'ils ne sont pas déjà presents dans la base\n",
    "                        if not dfJoueursBlesses.loc[~dfJoueursBlesses.nom.isin(dfJoueursBlessesBdd)].empty : \n",
    "                            #dfJoueursBlesses[['id_joueur']].assign(date_blessure=date).to_sql('blessure', c.sqlAlchemyConn, schema='donnees_source', if_exists='append', index=False)\n",
    "                            #print(f'blesse : {dfJoueursBlesses.nom.tolist()}')\n",
    "                            pass\n",
    "                            \n",
    "                    #checker si des joueurs ayant joué étaient noté blessé mais sont revenus\n",
    "\n",
    "                    #ensuite mettre en forme les stats de joueurs\n",
    "                    dfStatsJoueursBdd=dfJoueursTot[['minute', 'points', 'rebonds', 'passes_dec', 'steal',\n",
    "                       'contres', 'tir_reussi', 'tir_tentes', 'pct_tir', 'trois_pt_r',\n",
    "                       'trois_pt_t', 'pct_3_pt', 'lanc_frc_r', 'lanc_frc_t', 'pct_lfrc',\n",
    "                       'rebonds_o', 'rebonds_d', 'ball_perdu', 'faute_p', 'plus_moins', 'dnp',\n",
    "                       'blesse', 'score_ttfl', 'id_joueur']].copy()\n",
    "                    dfStatsJoueursBdd['id_match']=idMatch\n",
    "                    break\n",
    "        else :\n",
    "            continue\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfJoueurSansContrat.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_joueur</th>\n",
       "      <th>id_equipe</th>\n",
       "      <th>date_debut_contrat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>272</td>\n",
       "      <td>BKN</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211</td>\n",
       "      <td>BKN</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>330</td>\n",
       "      <td>BKN</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>BKN</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>306</td>\n",
       "      <td>BKN</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>88</td>\n",
       "      <td>BKN</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>500</td>\n",
       "      <td>BKN</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>348</td>\n",
       "      <td>BKN</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>256</td>\n",
       "      <td>BKN</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>467</td>\n",
       "      <td>BKN</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>452</td>\n",
       "      <td>BKN</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>147</td>\n",
       "      <td>BKN</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>363</td>\n",
       "      <td>BKN</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>342</td>\n",
       "      <td>BKN</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>323</td>\n",
       "      <td>BKN</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id_joueur id_equipe date_debut_contrat\n",
       "0         272       BKN         2020-12-22\n",
       "1         211       BKN         2020-12-22\n",
       "2         330       BKN         2020-12-22\n",
       "3         200       BKN         2020-12-22\n",
       "4         306       BKN         2020-12-22\n",
       "5          88       BKN         2020-12-22\n",
       "6         500       BKN         2020-12-22\n",
       "7         348       BKN         2020-12-22\n",
       "8         256       BKN         2020-12-22\n",
       "9         467       BKN         2020-12-22\n",
       "10        452       BKN         2020-12-22\n",
       "11        147       BKN         2020-12-22\n",
       "12        363       BKN         2020-12-22\n",
       "13        342       BKN         2020-12-22\n",
       "14        323       BKN         2020-12-22"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNewContrat.loc[dfNewContrat.date_debut_contrat==dfNewContrat.groupby('id_joueur').date_debut_contrat.transform('max')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMatchCsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "idEquipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MetaData(bind=None)\n"
     ]
    }
   ],
   "source": [
    "with ct.ConnexionBdd('basket','maison') as c:\n",
    "    meta = MetaData()\n",
    "    meta.reflect(bind=c.sqlAlchemyConn)\n",
    "    print(meta)\n",
    "    for table in reversed(meta.sorted_tables):\n",
    "        print(meta,table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetaData(bind=None)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. exemple de blessure\n",
    "le joueur Markelle Fultz s'est fait une rupture des ligaments croisé, exemple d'insertion dans la table blessure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomJoueurBlesse='Markelle Fultz'\n",
    "idTypeBlessure=1\n",
    "dateBlessure='2021-06-01'\n",
    "requeteBlessure = f\"\"\"insert into donnees_source.blessure(id_joueur,id_type_blessure,date_blessure) \n",
    "             select id_joueur,{idTypeBlessure},{dateBlessure} from donnees_source.joueur where lower(nom)=lower{nomJoueurBlesse}\"\"\"\n",
    "with ct.ConnexionBdd('basket','maison') as c : \n",
    "    c.execute(c.sqlAlchemyConn,requeteBlessure)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
