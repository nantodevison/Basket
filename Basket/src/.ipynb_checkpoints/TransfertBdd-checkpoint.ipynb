{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Notebook de transfert des donnees du site nba.com depuis le site ou un fichier intermediaire**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import sys, os, re, time #c'est pas propre mais pour le moment pour importer mes modules perso dans le notebook je ne sais pas faire\n",
    "sys.path.append(r'C:\\Users\\martin.schoreisz\\git\\Outils\\Outils\\Martin_Perso')\n",
    "import Connexion_Transfert as ct\n",
    "\n",
    "from datetime import datetime\n",
    "from TelechargementDonnees import JoueursSiteNba, DriverFirefox, gererCookie,simplifierNomJoueur\n",
    "from sqlalchemy import MetaData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Données de joueurs \n",
    "Il s'agit de transfere dans le cas des donnees de joueuer telechargees en amont, ou d'ajouter des joueurs non presents au moment d'insertion de match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">## 1.1 Enumerations des types de position\n",
    "A creer a la main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation de la classe\n",
    "pagejoueuer=JoueursSiteNba(urlPageJoueurs='https://www.nba.com/player/1630173/precious-achiuwa',typeExport='One' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taille</th>\n",
       "      <th>poids</th>\n",
       "      <th>date_entree_nba</th>\n",
       "      <th>date_naissance</th>\n",
       "      <th>nom</th>\n",
       "      <th>nom_simple</th>\n",
       "      <th>id_position_terrain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.03</td>\n",
       "      <td>102.0</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>1999-09-19</td>\n",
       "      <td>Precious Achiuwa</td>\n",
       "      <td>preciousachiuwa</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   taille  poids date_entree_nba date_naissance               nom  \\\n",
       "0    2.03  102.0      2020-10-01     1999-09-19  Precious Achiuwa   \n",
       "\n",
       "        nom_simple id_position_terrain  \n",
       "0  preciousachiuwa                   F  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pagejoueuer.dfJoueurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ct.ConnexionBdd('basket','maison') as c : \n",
    "    pd.DataFrame({'id_position_terrain':[e for e in pagejoueuer.dfJoueurs.id_position_terrain.unique() if e in ('F', 'G', 'C', 'C-F', 'F-G', 'G-F', 'F-C')]+['NC'], \n",
    "              'nom_position_terrain':['Forward ; 3 ; ailier', 'Guard ; 1 ou 2  ; meneur ou arriere', \n",
    "                                      'Center ; 5 ; Pivot' ,'Power Forward ; 4 ; ailier Fort', \n",
    "                                      'Shooting Guard ; 2 ; arriere', 'Shooting Guard ; 2 ; arriere',\n",
    "                                      'Power Forward ; 4 ; ailier Fort', 'Non connue']}).to_sql(\n",
    "        'enum_position_terrain', c.sqlAlchemyConn, schema='donnees_source', if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## 1.2 Donnees chargees depuis la page internet\n",
    "Là ce n'est que le premier import, on ne gère pas la mise à jour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfert dans la Bdd\n",
    "with ct.ConnexionBdd('basket','maison') as c : \n",
    "    pagejoueuer.dfJoueurs[['nom','id_position_terrain','taille', 'poids','date_entree_nba','nom_simple']].to_sql(\n",
    "        'joueur', c.sqlAlchemyConn, schema='donnees_source', if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Données d'équipe\n",
    "On utilise les données de joueurs pour faire la liste des equipes, et on complete avec les divisions et conférence, puis on transfere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicoNom={'MIA':'Miami Heat','MIL':'Milwaukee Bucks','NOP':'New-Orleans Pelicans','SAS':'San-Antonio Spurs',\n",
    "'PHX':'Phoenix','MEM':'Memphis Grizzlies',    'BKN':'Brooklyn Nets','ORL':'Orlando Magic','LAL':'LosAngeles Lakers','POR':'Portland TrailBlazzers','TOR':'Toronto Raptors','CHI':'Chicago Bulls',\n",
    "'OKC':'Oklahoma City Thunder','WAS':'Washington Wizards','UTA':'Utah Jazz','SAC':'Sacramento Kings','CHA':'Charlotte Hornets','NYK':'New-York Knicks','DEN':'Denver Nuggets',\n",
    "'LAC':'Los Angeles Clippers','GSW':'Golden State Warriors','MIN':'Minessota TimberWolves','DET':'Detroit Pistons','DAL':'Dallas Mavericks',\n",
    "'IND':'Indiana Pacers','ATL':'Atlanta Hawks','CLE':'Cleveland Cavaliers','PHI':'Philadelphia Sixers','BOS':'Boston Celtics','HOU':'Houston Rockets'}\n",
    "list_equipe=dicoNom.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicoDivision={'Central Division': ['MIL', 'CHI', 'IND', 'CLE', 'DET'],'Atlantic Division': ['BOS', 'BKN', 'NYK', 'TOR', \n",
    "'PHI'],'Southeast Division' : ['MIA', 'ORL', 'WAS', 'CHA', 'ATL'],'Southwest Division': ['SAS', 'HOU', 'DAL', 'NOP', \n",
    "'MEM'],'Northwest Division' : ['DEN', 'MIN', 'OKC', 'POR', 'UTA'],'Pacific Division' : ['LAC', 'LAL', 'PHX', 'GSW', 'SAC']}\n",
    "listDivision=[k for e in list_equipe for k,v in dicoDivision.items()  if e in v] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicoConference={'Ouest' : ['SAS', 'HOU', 'DAL', 'NOP', 'MEM','DEN', 'MIN', 'OKC', 'POR', 'UTA','LAC', 'LAL', 'PHX', \n",
    "    'GSW', 'SAC'],'Est':['MIL', 'CHI', 'IND', 'CLE', 'DET','BOS', 'BKN', 'NYK', 'TOR', 'PHI','MIA', \n",
    "                         'ORL', 'WAS', 'CHA', 'ATL']}\n",
    "\n",
    "listConference=[k for e in list_equipe for k,v in dicoConference.items()  if e in v] \n",
    "listNom=[v for k,v in dicoNom.items() for e in list_equipe if k==e] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ct.ConnexionBdd('basket','boulot') as c : \n",
    "    pd.DataFrame({'id_equipe':list_equipe,'nom_equipe': listNom,\n",
    "              'conference':listConference, 'division':listDivision}).to_sql(\n",
    "        'equipe', c.sqlAlchemyConn, schema='donnees_source', if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Données de match\n",
    "Dans un premier temp on va lire les fichiers csv stcokés [ici](C:\\Users\\martin.schoreisz\\Documents\\AffairesEnCours\\temp\\basket)\n",
    "L'idée c'est d'avoir une classe match, qui va regrouper : \n",
    "- les df de matchs, statjoueur, stat\n",
    "- va falloir gérer les contrats : \n",
    "    - l'id_joueur n'est pas dans contrat : -> on cree une ligne avec id_equip, id_joueur, date_debut_contrat à  minima\n",
    "    - l'id_joueur est dans contrat : \n",
    "        - trouver la date la plus recente\n",
    "        - obtenir l'equipe en cours\n",
    "        - comparer avec equipe actuelle : \n",
    "            - equipe identiques : on fait rien\n",
    "            - equipe differente : \n",
    "                - update date_fin_contrat sur la ligne la plus recente\n",
    "                - creer une nouvelle ligne contrat avec id_equip, id_joueur, date_debut_contrat\n",
    "- va falloir trier les joueuers qui n'ont pas joué avant de les basculer dans les stats joueur (attribut dnp)\n",
    "- va falloir trouver les joueurs non contenus dans la base des joueurs et les ajouter (nom à minima)\n",
    "- va falloir gérer les blessures  : \n",
    "> - les ajouter à la table blessure si elle ne sont pas déjà dedans\n",
    "> - noter comme apte les joueurs présents dans la table blessure, dont la date de guérison n'est pas connue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dossierBase=r'C:\\Users\\martin.schoreisz\\git\\Basket\\Basket\\data\\testUsa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-22\n",
      "2020-12-23\n",
      "blesse : ['Dario Saric']\n",
      "2020-12-25\n",
      "2020-12-26\n",
      "blesse : ['Danilo Gallinari']\n",
      "blesse : ['Xavier Tillman']\n",
      "2020-12-27\n",
      "blesse : ['Kawhi Leonard']\n",
      "blesse : ['Joel Embiid']\n",
      "blesse : ['Jalen Smith']\n",
      "2020-12-28\n",
      "blesse : ['Jahlil Okafor']\n",
      "2020-12-29\n",
      "blesse : ['Alec Burks']\n",
      "retour blessure : ['Joel Embiid']\n",
      "retour blessure : ['Dario Saric']\n",
      "blesse : ['Jamal Murray']\n",
      "2020-12-30\n",
      "blesse : ['Jontay Porter']\n",
      "retour blessure : ['Danilo Gallinari']\n",
      "retour blessure : ['Kawhi Leonard']\n",
      "2020-12-31\n",
      "2021-01-01\n",
      "blesse : ['Grayson Allen']\n",
      "blesse : ['Danilo Gallinari']\n",
      "blesse : ['Dario Saric']\n",
      "retour blessure : ['Jamal Murray']\n",
      "2021-01-02\n",
      "blesse : ['James Harden']\n",
      "2021-01-03\n",
      "retour blessure : ['Jahlil Okafor']\n",
      "retour blessure : ['Grayson Allen', 'Xavier Tillman']\n",
      "blesse : ['Luka Doncic']\n",
      "blesse : ['Marcus Morris Sr.']\n",
      "retour blessure : ['Dario Saric']\n",
      "2021-01-04\n",
      "blesse : ['Darius Garland']\n",
      "blesse : ['Nerlens Noel']\n",
      "retour blessure : ['Luka Doncic']\n",
      "retour blessure : ['James Harden']\n",
      "2021-01-05\n",
      "blesse : ['Rodions Kurucs']\n",
      "blesse : ['John Konchar']\n",
      "blesse : ['Paul George']\n",
      "2021-01-06\n",
      "blesse : ['Ben McLemore', 'Christian Wood']\n",
      "blesse : ['Evan Fournier']\n",
      "retour blessure : ['Paul George', 'Marcus Morris Sr.']\n",
      "2021-01-07\n",
      "retour blessure : ['Rodions Kurucs']\n",
      "blesse : ['Collin Sexton']\n",
      "2021-01-08\n",
      "retour blessure : ['Nerlens Noel']\n",
      "blesse : ['Aaron Gordon']\n",
      "retour blessure : ['Christian Wood', 'Ben McLemore']\n",
      "2021-01-09\n",
      "blesse : ['Furkan Korkmaz']\n",
      "blesse : ['Cameron Payne']\n",
      "blesse : ['Russell Westbrook']\n",
      "retour blessure : ['Aaron Gordon']\n",
      "blesse : ['Richaun Holmes']\n",
      "2021-01-10\n",
      "blesse : ['Wesley Matthews']\n",
      "2021-01-11\n",
      "retour blessure : ['Richaun Holmes']\n",
      "2021-01-12\n",
      "blesse : ['Meyers Leonard']\n",
      "blesse : ['Andre Drummond']\n",
      "blesse : ['Victor Oladipo']\n",
      "2021-01-13\n",
      "blesse : ['Nicolas Claxton', 'Spencer Dinwiddie']\n",
      "2021-01-14\n",
      "blesse : ['Gordon Hayward']\n",
      "blesse : ['Eric Gordon', 'John Wall']\n",
      "blesse : ['Jalen Lecque']\n",
      "2021-01-15\n",
      "blesse : ['Dylan Windler']\n",
      "retour blessure : ['Andre Drummond']\n",
      "retour blessure : ['Wesley Matthews']\n",
      "blesse : ['Lou Williams']\n",
      "2021-01-16\n",
      "blesse : ['Sterling Brown', 'DeMarcus Cousins']\n",
      "blesse : ['Luka Samanic']\n",
      "retour blessure : ['Gordon Hayward']\n",
      "blesse : ['Tyler Herro']\n",
      "blesse : ['Mike Scott']\n",
      "blesse : ['Cam Reddish']\n",
      "blesse : ['CJ Elleby']\n",
      "2021-01-17\n",
      "blesse : ['Tim Hardaway Jr.']\n",
      "retour blessure : ['Jalen Lecque']\n",
      "2021-01-18\n",
      "retour blessure : ['Cameron Payne']\n",
      "retour blessure : ['John Konchar']\n",
      "retour blessure : ['Tim Hardaway Jr.']\n",
      "retour blessure : ['Eric Gordon', 'Victor Oladipo', 'DeMarcus Cousins']\n",
      "2021-01-19\n",
      "2021-01-20\n",
      "retour blessure : ['Collin Sexton']\n",
      "retour blessure : ['Furkan Korkmaz']\n",
      "blesse : [\"De'Andre Hunter\"]\n",
      "retour blessure : ['Evan Fournier']\n",
      "retour blessure : ['Sterling Brown']\n",
      "retour blessure : ['Lou Williams']\n"
     ]
    }
   ],
   "source": [
    "with ct.ConnexionBdd('basket','maison') as c:\n",
    "    with os.scandir(dossierBase) as it : \n",
    "        for entry in it:\n",
    "            #paramètres généraux par date\n",
    "            date=entry.name\n",
    "            id_type_match=0\n",
    "            id_saison=1\n",
    "            root=os.path.join(dossierBase,date)\n",
    "            \n",
    "            #recuperer les données de joueurs, blesses et les contrat avant la journee\n",
    "            dfJoueursBdd=pd.read_sql('select id_joueur, nom_simple from donnees_source.joueur',c.sqlAlchemyConn)\n",
    "            dfContratBdd=pd.read_sql(\"SELECT * FROM donnees_source.contrat WHERE date_fin_contrat IS null\",c.sqlAlchemyConn)\n",
    "            dfJoueursBlessesBdd=pd.read_sql(\"select * from donnees_source.blessure WHERE date_guerison IS NULL\",c.sqlAlchemyConn)\n",
    "            print(date)\n",
    "            \n",
    "            for f in [entry.name for entry in os.scandir(root) if entry.is_file() and 'equipe' not in entry.name and entry.name.endswith('.csv')] :\n",
    "                #recuperer l'id_match : \n",
    "                idMatchBdd=c.sqlAlchemyConn.execute(\"SELECT last_value FROM donnees_source.match_id_match_seq\").fetchone()[0] \n",
    "                #recuperer l'identifiant du match dans le dossier contenant les fichiers\n",
    "                groupe=f.split('_')[0][1:]\n",
    "                \n",
    "                \n",
    "                #lire le fichier csv du match, transformer pour remplir la table des matchs\n",
    "                dfMatchCsv=pd.read_csv(root+os.sep+f).rename(columns={'equipe':'id_equipe'})\n",
    "                equipeExt=dfMatchCsv.iloc[0].id_equipe\n",
    "                equipeDom=dfMatchCsv.iloc[1].id_equipe\n",
    "                dfMatchBdd=pd.DataFrame({'id_saison':[id_saison],\n",
    "                                      'date_match':[date], \n",
    "                                      'equipe_domicile':[equipeDom], \n",
    "                                      'equipe_exterieure':[equipeExt],\n",
    "                                      'id_type_match':[id_type_match],\n",
    "                                        'id_match':idMatchBdd})\n",
    "                #melt la table csv pour remplir la table des scores de match\n",
    "                dfScoreMatch=dfMatchCsv.melt(id_vars=['id_equipe'], value_vars=['q1','q2','q3','q4','final'],\n",
    "                            var_name='id_periode', value_name='score_periode').sort_values('id_equipe')\n",
    "                dfScoreMatch['id_match']=idMatchBdd\n",
    "                \n",
    "                \n",
    "                \n",
    "                #maintenant il faut lire les fichiers stats_equipe associés\n",
    "                for i in (0,1) : \n",
    "                    nomFichierEquipe=f'm{groupe}_equipe{i}_{date}.csv'\n",
    "                    dfStatsJoueursCsv=pd.read_csv(os.path.join(root,nomFichierEquipe))\n",
    "                    idEquipe=dfMatchCsv.loc[i].id_equipe\n",
    "                    \n",
    "                    \n",
    "                    #pensez à enlever du fichier source les joueurs n'ayant pas joué et non blesse avant de creer la df des statsJoueur: \n",
    "                    dfStatsJoueursActifCsv=dfStatsJoueursCsv.loc[(~dfStatsJoueursCsv['dnp']) | dfStatsJoueursCsv['blesse']]\n",
    "                    \n",
    "                    #le pb ça va etre de recuperer les id_joueurs, va falloir telecharger d'abords la table de correspondance\n",
    "                    #faire la jointure en amont et ensuite on bascule tout le monde\n",
    "                    dfJoueursTot=dfStatsJoueursActifCsv.merge(dfJoueursBdd, on='nom_simple', how='left')                \n",
    "\n",
    "                    #pensez à checker si tous les joueurs sont présents dans la base joueur, et les ajouter si ils n'y sont pas\n",
    "                    dfJoueurInconnus=dfJoueursTot.loc[dfJoueursTot.id_joueur.isna()]\n",
    "                    if not dfJoueurInconnus.empty : \n",
    "                        dfJoueurInconnus=dfJoueurInconnus[['nom','nom_simple']]\n",
    "                        #basculer dans Bdd\n",
    "                        #dfJoueurInconnus.to_sql('joueur', c.sqlAlchemyConn, schema='donnees_source', if_exists='append', index=False)\n",
    "                        print(f'nouveau joueur : {dfJoueurInconnus.nom.tolist()} equipe {i}')\n",
    "                    #refaire un import et jointure au cas où des joueurs aient été ajoutés dans table joueurs, idem pour les contrats\n",
    "                    dfJoueursBdd=pd.read_sql('select id_joueur, nom_simple from donnees_source.joueur',c.sqlAlchemyConn)\n",
    "                    dfJoueursTot=dfStatsJoueursActifCsv.merge(dfJoueursBdd, on='nom_simple')\n",
    "                    \n",
    "                    \n",
    "                    \"\"\"#contrat : \n",
    "                    #1.verifier si id_joueur dans la base contrat : \n",
    "                    dfJoueurSansContrat=dfJoueursTot.loc[~dfJoueursTot.id_joueur.isin(dfContratBdd.id_joueur.tolist())]\n",
    "                    if not dfJoueurSansContrat.empty : #joueur sans contrat\n",
    "                        dfNewContrat=pd.DataFrame({'id_joueur':dfJoueurSansContrat.id_joueur.tolist(),'id_equipe':idEquipe,'date_debut_contrat':date})\n",
    "                        dfNewContrat.to_sql('contrat',c.sqlAlchemyConn, schema='donnees_source', if_exists='append', index=False)\n",
    "                    #joueur avec contrat : \n",
    "                    #jointure entre la table contratBdd et celle du match sur id_joueur pour comparer les equipes\n",
    "                    if not dfContratBdd.empty : \n",
    "                        dfContratJoueurMatch=dfContratBdd.merge(dfJoueursTot[['id_joueur']], on='id_joueur')\n",
    "                        dfContratJoueurChange=dfContratJoueurMatch.loc[dfContratJoueurMatch.id_equipe!=idEquipe]\n",
    "                        if not dfContratJoueurChange.empty: #si un joueur a changé d'équipe\n",
    "                            dateFinContrat=(pd.to_datetime(date)-pd.Timedelta(1,'day')).strftime('%Y-%m-%d')\n",
    "                            print(dfContratJoueurChange.id_joueur, dateFinContrat)\n",
    "                            #il faut update la table avec la valeur de date en date_fin_contrat\n",
    "                            c.sqlAlchemyConn.execute(f\"UPDATE donnees_source.contrat SET date_fin_contrat = '{dateFinContrat}' WHERE id_contrat=any(array{dfContratJoueurChange.id_contrat.tolist()})\")\n",
    "                            #et inserer de nouvelle lignes\n",
    "                            pd.DataFrame({'id_joueur':dfContratJoueurChange.id_joueur.tolist(),'id_equipe':idEquipe,'date_debut_contrat':date}).to_sql('contrat',c.sqlAlchemyConn, schema='donnees_source', if_exists='append', index=False)\"\"\"\n",
    "                            \n",
    "                    \n",
    "                    \"\"\"#Blessure\n",
    "                    #checker si des joueurs sont notés blessé et ne sont pas déjà dans la base blessure\n",
    "                    dfJoueursBlesses=dfJoueursTot.loc[dfJoueursTot['blesse']]\n",
    "                    if not dfJoueursBlesses.empty : #si des joueurs blesses, verifier qu'ils ne sont pas déjà presents dans la base\n",
    "                        dfNouveauBlesse=dfJoueursBlesses.loc[~dfJoueursBlesses.id_joueur.isin(dfJoueursBlessesBdd.id_joueur.tolist())]\n",
    "                        if not dfNouveauBlesse.empty : \n",
    "                            dfJoueursBlesses=dfJoueursBlesses.loc[~dfJoueursBlesses.id_joueur.isin(dfJoueursBlessesBdd.id_joueur.tolist())].copy()\n",
    "                            dfNouveauBlesse[['id_joueur']].assign(date_blessure=date, id_type_blessure=99).to_sql('blessure', c.sqlAlchemyConn, schema='donnees_source', if_exists='append', index=False)\n",
    "                            print(f'blesse : {dfNouveauBlesse.nom.tolist()}')        \n",
    "                    #checker si des joueurs ayant joué étaient noté blessé mais sont revenus\n",
    "                    dfJoueurRetourBlessure=dfJoueursTot.loc[(dfJoueursTot.id_joueur.isin(dfJoueursBlessesBdd.id_joueur.tolist())) & (~dfJoueursTot['blesse'])]\n",
    "                    if not dfJoueurRetourBlessure.empty : #si des retours\n",
    "                        dateGuerison=(pd.to_datetime(date)-pd.Timedelta(1,'day')).strftime('%Y-%m-%d')\n",
    "                        #il faut update la table avec la valeur de date en date_fin_blessurre\n",
    "                        c.sqlAlchemyConn.execute(f\"UPDATE donnees_source.blessure SET date_guerison = '{dateGuerison}' WHERE id_joueur=any(array{dfJoueurRetourBlessure.id_joueur.tolist()}) AND date_guerison is null\")\n",
    "                        print(f'retour blessure : {dfJoueurRetourBlessure.nom.tolist()}')\"\"\"\n",
    "\n",
    "                    #ensuite mettre en forme les stats de joueurs\n",
    "                    dfStatsJoueursBdd=dfJoueursTot.loc[~dfJoueursTot['dnp'][['minute', 'points', 'rebonds', 'passes_dec', 'steal',\n",
    "                       'contres', 'tir_reussi', 'tir_tentes', 'pct_tir', 'trois_pt_r',\n",
    "                       'trois_pt_t', 'pct_3_pt', 'lanc_frc_r', 'lanc_frc_t', 'pct_lfrc',\n",
    "                       'rebonds_o', 'rebonds_d', 'ball_perdu', 'faute_p', 'plus_moins','score_ttfl', 'id_joueur']].copy()\n",
    "                    dfStatsJoueursBdd['id_match']=idMatchBdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nom</th>\n",
       "      <th>minute</th>\n",
       "      <th>tir_reussi</th>\n",
       "      <th>tir_tentes</th>\n",
       "      <th>pct_tir</th>\n",
       "      <th>trois_pt_r</th>\n",
       "      <th>trois_pt_t</th>\n",
       "      <th>pct_3_pt</th>\n",
       "      <th>lanc_frc_r</th>\n",
       "      <th>lanc_frc_t</th>\n",
       "      <th>...</th>\n",
       "      <th>contres</th>\n",
       "      <th>ball_perdu</th>\n",
       "      <th>faute_p</th>\n",
       "      <th>points</th>\n",
       "      <th>plus_moins</th>\n",
       "      <th>dnp</th>\n",
       "      <th>blesse</th>\n",
       "      <th>nom_simple</th>\n",
       "      <th>score_ttfl</th>\n",
       "      <th>id_joueur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [nom, minute, tir_reussi, tir_tentes, pct_tir, trois_pt_r, trois_pt_t, pct_3_pt, lanc_frc_r, lanc_frc_t, pct_lfrc, rebonds_o, rebonds_d, rebonds, passes_dec, steal, contres, ball_perdu, faute_p, points, plus_moins, dnp, blesse, nom_simple, score_ttfl, id_joueur]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 26 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNouveauBlesse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m0_2020-12-22.csv\n",
      "2020-12-22 ; GSW\n",
      "m1_2020-12-22.csv\n",
      "2020-12-22 ; LAC\n",
      "m0_2020-12-23.csv\n",
      "2020-12-23 ; CHA\n",
      "m10_2020-12-23.csv\n",
      "2020-12-23 ; UTA\n",
      "m11_2020-12-23.csv\n",
      "2020-12-23 ; DAL\n",
      "m1_2020-12-23.csv\n",
      "2020-12-23 ; NYK\n",
      "m2_2020-12-23.csv\n",
      "2020-12-23 ; MIA\n",
      "m3_2020-12-23.csv\n",
      "2020-12-23 ; WAS\n",
      "m4_2020-12-23.csv\n",
      "2020-12-23 ; MIL\n",
      "m5_2020-12-23.csv\n",
      "2020-12-23 ; NOP\n",
      "m6_2020-12-23.csv\n",
      "2020-12-23 ; ATL\n",
      "m7_2020-12-23.csv\n",
      "2020-12-23 ; SAS\n",
      "m8_2020-12-23.csv\n",
      "2020-12-23 ; DET\n",
      "m9_2020-12-23.csv\n",
      "2020-12-23 ; SAC\n",
      "m0_2020-12-25.csv\n",
      "2020-12-25 ; NOP\n",
      "m1_2020-12-25.csv\n",
      "2020-12-25 ; GSW\n",
      "m2_2020-12-25.csv\n",
      "2020-12-25 ; BKN\n",
      "m3_2020-12-25.csv\n",
      "2020-12-25 ; DAL\n",
      "m4_2020-12-25.csv\n",
      "2020-12-25 ; LAC\n",
      "m0_2020-12-26.csv\n",
      "2020-12-26 ; ATL\n",
      "m1_2020-12-26.csv\n",
      "2020-12-26 ; OKC\n",
      "m2_2020-12-26.csv\n",
      "2020-12-26 ; CLE\n",
      "m3_2020-12-26.csv\n",
      "2020-12-26 ; ORL\n",
      "m4_2020-12-26.csv\n",
      "2020-12-26 ; PHI\n",
      "m5_2020-12-26.csv\n",
      "2020-12-26 ; IND\n",
      "m6_2020-12-26.csv\n",
      "2020-12-26 ; TOR\n",
      "m7_2020-12-26.csv\n",
      "2020-12-26 ; MIN\n",
      "m8_2020-12-26.csv\n",
      "2020-12-26 ; HOU\n",
      "m9_2020-12-26.csv\n",
      "2020-12-26 ; PHX\n",
      "m0_2020-12-27.csv\n",
      "2020-12-27 ; DAL\n",
      "m1_2020-12-27.csv\n",
      "2020-12-27 ; BKN\n",
      "m2_2020-12-27.csv\n",
      "2020-12-27 ; ORL\n",
      "m3_2020-12-27.csv\n",
      "2020-12-27 ; SAS\n",
      "m4_2020-12-27.csv\n",
      "2020-12-27 ; PHI\n",
      "m5_2020-12-27.csv\n",
      "2020-12-27 ; MIL\n",
      "m6_2020-12-27.csv\n",
      "2020-12-27 ; BOS\n",
      "m7_2020-12-27.csv\n",
      "2020-12-27 ; GSW\n",
      "m8_2020-12-27.csv\n",
      "2020-12-27 ; PHX\n",
      "m9_2020-12-27.csv\n",
      "2020-12-27 ; MIN\n",
      "m0_2020-12-28.csv\n",
      "2020-12-28 ; DET\n",
      "m1_2020-12-28.csv\n",
      "2020-12-28 ; MEM\n",
      "m2_2020-12-28.csv\n",
      "2020-12-28 ; UTA\n",
      "m3_2020-12-28.csv\n",
      "2020-12-28 ; HOU\n",
      "m4_2020-12-28.csv\n",
      "2020-12-28 ; POR\n",
      "m0_2020-12-29.csv\n",
      "2020-12-29 ; NYK\n",
      "m1_2020-12-29.csv\n",
      "2020-12-29 ; GSW\n",
      "m2_2020-12-29.csv\n",
      "2020-12-29 ; BOS\n",
      "m3_2020-12-29.csv\n",
      "2020-12-29 ; TOR\n",
      "m4_2020-12-29.csv\n",
      "2020-12-29 ; CHI\n",
      "m5_2020-12-29.csv\n",
      "2020-12-29 ; MIL\n",
      "m6_2020-12-29.csv\n",
      "2020-12-29 ; ORL\n",
      "m7_2020-12-29.csv\n",
      "2020-12-29 ; NOP\n",
      "m8_2020-12-29.csv\n",
      "2020-12-29 ; MIN\n",
      "m9_2020-12-29.csv\n",
      "2020-12-29 ; DEN\n",
      "m0_2020-12-30.csv\n",
      "2020-12-30 ; MEM\n",
      "m1_2020-12-30.csv\n",
      "2020-12-30 ; ATL\n",
      "m2_2020-12-30.csv\n",
      "2020-12-30 ; MIL\n",
      "m3_2020-12-30.csv\n",
      "2020-12-30 ; CHA\n",
      "m4_2020-12-30.csv\n",
      "2020-12-30 ; LAL\n",
      "m5_2020-12-30.csv\n",
      "2020-12-30 ; POR\n",
      "m0_2020-12-31.csv\n",
      "2020-12-31 ; CLE\n",
      "m1_2020-12-31.csv\n",
      "2020-12-31 ; CHI\n",
      "m2_2020-12-31.csv\n",
      "2020-12-31 ; PHI\n",
      "m3_2020-12-31.csv\n",
      "2020-12-31 ; SAC\n",
      "m4_2020-12-31.csv\n",
      "2020-12-31 ; NYK\n",
      "m5_2020-12-31.csv\n",
      "2020-12-31 ; NOP\n",
      "m6_2020-12-31.csv\n",
      "2020-12-31 ; PHX\n",
      "m0_2021-01-01.csv\n",
      "2021-01-01 ; MEM\n",
      "m1_2021-01-01.csv\n",
      "2021-01-01 ; BOS\n",
      "m2_2021-01-01.csv\n",
      "2021-01-01 ; MIA\n",
      "m3_2021-01-01.csv\n",
      "2021-01-01 ; ATL\n",
      "m4_2021-01-01.csv\n",
      "2021-01-01 ; CHI\n",
      "m5_2021-01-01.csv\n",
      "2021-01-01 ; WAS\n",
      "m6_2021-01-01.csv\n",
      "2021-01-01 ; LAL\n",
      "m7_2021-01-01.csv\n",
      "2021-01-01 ; PHX\n",
      "m8_2021-01-01.csv\n",
      "2021-01-01 ; LAC\n",
      "m9_2021-01-01.csv\n",
      "2021-01-01 ; POR\n",
      "m0_2021-01-02.csv\n",
      "2021-01-02 ; SAC\n",
      "m1_2021-01-02.csv\n",
      "2021-01-02 ; NYK\n",
      "m2_2021-01-02.csv\n",
      "2021-01-02 ; OKC\n",
      "m3_2021-01-02.csv\n",
      "2021-01-02 ; CHA\n",
      "m4_2021-01-02.csv\n",
      "2021-01-02 ; CLE\n",
      "m5_2021-01-02.csv\n",
      "2021-01-02 ; TOR\n",
      "m0_2021-01-03.csv\n",
      "2021-01-03 ; BOS\n",
      "m1_2021-01-03.csv\n",
      "2021-01-03 ; WAS\n",
      "m2_2021-01-03.csv\n",
      "2021-01-03 ; LAL\n",
      "m3_2021-01-03.csv\n",
      "2021-01-03 ; DEN\n",
      "m4_2021-01-03.csv\n",
      "2021-01-03 ; UTA\n",
      "m5_2021-01-03.csv\n",
      "2021-01-03 ; DAL\n",
      "m6_2021-01-03.csv\n",
      "2021-01-03 ; LAC\n",
      "m7_2021-01-03.csv\n",
      "2021-01-03 ; POR\n",
      "m0_2021-01-04.csv\n",
      "2021-01-04 ; CLE\n",
      "m1_2021-01-04.csv\n",
      "2021-01-04 ; CHA\n",
      "m2_2021-01-04.csv\n",
      "2021-01-04 ; NYK\n",
      "m3_2021-01-04.csv\n",
      "2021-01-04 ; OKC\n",
      "m4_2021-01-04.csv\n",
      "2021-01-04 ; BOS\n",
      "m5_2021-01-04.csv\n",
      "2021-01-04 ; DAL\n",
      "m6_2021-01-04.csv\n",
      "2021-01-04 ; DET\n",
      "m7_2021-01-04.csv\n",
      "2021-01-04 ; IND\n",
      "m8_2021-01-04.csv\n",
      "2021-01-04 ; SAC\n",
      "m0_2021-01-05.csv\n",
      "2021-01-05 ; UTA\n",
      "m1_2021-01-05.csv\n",
      "2021-01-05 ; LAL\n",
      "m2_2021-01-05.csv\n",
      "2021-01-05 ; MIN\n",
      "m3_2021-01-05.csv\n",
      "2021-01-05 ; SAS\n",
      "m4_2021-01-05.csv\n",
      "2021-01-05 ; CHI\n",
      "m0_2021-01-06.csv\n",
      "2021-01-06 ; HOU\n",
      "m10_2021-01-06.csv\n",
      "2021-01-06 ; CHI\n",
      "m1_2021-01-06.csv\n",
      "2021-01-06 ; CLE\n",
      "m2_2021-01-06.csv\n",
      "2021-01-06 ; WAS\n",
      "m3_2021-01-06.csv\n",
      "2021-01-06 ; CHA\n",
      "m4_2021-01-06.csv\n",
      "2021-01-06 ; BOS\n",
      "m5_2021-01-06.csv\n",
      "2021-01-06 ; UTA\n",
      "m6_2021-01-06.csv\n",
      "2021-01-06 ; DET\n",
      "m7_2021-01-06.csv\n",
      "2021-01-06 ; OKC\n",
      "m8_2021-01-06.csv\n",
      "2021-01-06 ; TOR\n",
      "m9_2021-01-06.csv\n",
      "2021-01-06 ; LAC\n",
      "m0_2021-01-07.csv\n",
      "2021-01-07 ; PHI\n",
      "m1_2021-01-07.csv\n",
      "2021-01-07 ; CLE\n",
      "m2_2021-01-07.csv\n",
      "2021-01-07 ; DAL\n",
      "m3_2021-01-07.csv\n",
      "2021-01-07 ; SAS\n",
      "m4_2021-01-07.csv\n",
      "2021-01-07 ; MIN\n",
      "m0_2021-01-08.csv\n",
      "2021-01-08 ; PHX\n",
      "m1_2021-01-08.csv\n",
      "2021-01-08 ; WAS\n",
      "m2_2021-01-08.csv\n",
      "2021-01-08 ; OKC\n",
      "m3_2021-01-08.csv\n",
      "2021-01-08 ; CHA\n",
      "m4_2021-01-08.csv\n",
      "2021-01-08 ; ORL\n",
      "m5_2021-01-08.csv\n",
      "2021-01-08 ; BKN\n",
      "m6_2021-01-08.csv\n",
      "2021-01-08 ; UTA\n",
      "m7_2021-01-08.csv\n",
      "2021-01-08 ; LAC\n",
      "m8_2021-01-08.csv\n",
      "2021-01-08 ; CHI\n",
      "m9_2021-01-08.csv\n",
      "2021-01-08 ; TOR\n",
      "m0_2021-01-09.csv\n",
      "2021-01-09 ; DEN\n",
      "m1_2021-01-09.csv\n",
      "2021-01-09 ; ATL\n",
      "m2_2021-01-09.csv\n",
      "2021-01-09 ; PHX\n",
      "m3_2021-01-09.csv\n",
      "2021-01-09 ; MIA\n",
      "m4_2021-01-09.csv\n",
      "2021-01-09 ; CLE\n",
      "m5_2021-01-09.csv\n",
      "2021-01-09 ; SAS\n",
      "m6_2021-01-09.csv\n",
      "2021-01-09 ; ORL\n",
      "m7_2021-01-09.csv\n",
      "2021-01-09 ; POR\n",
      "m0_2021-01-10.csv\n",
      "2021-01-10 ; UTA\n",
      "m1_2021-01-10.csv\n",
      "2021-01-10 ; CHI\n",
      "m2_2021-01-10.csv\n",
      "2021-01-10 ; OKC\n",
      "m3_2021-01-10.csv\n",
      "2021-01-10 ; DEN\n",
      "m4_2021-01-10.csv\n",
      "2021-01-10 ; LAL\n",
      "m5_2021-01-10.csv\n",
      "2021-01-10 ; SAS\n",
      "m6_2021-01-10.csv\n",
      "2021-01-10 ; TOR\n",
      "m0_2021-01-11.csv\n",
      "2021-01-11 ; NYK\n",
      "m1_2021-01-11.csv\n",
      "2021-01-11 ; MEM\n",
      "m2_2021-01-11.csv\n",
      "2021-01-11 ; MIL\n",
      "m3_2021-01-11.csv\n",
      "2021-01-11 ; PHX\n",
      "m4_2021-01-11.csv\n",
      "2021-01-11 ; PHI\n",
      "m5_2021-01-11.csv\n",
      "2021-01-11 ; TOR\n",
      "m6_2021-01-11.csv\n",
      "2021-01-11 ; IND\n",
      "m0_2021-01-12.csv\n",
      "2021-01-12 ; MIA\n",
      "m1_2021-01-12.csv\n",
      "2021-01-12 ; DEN\n",
      "m2_2021-01-12.csv\n",
      "2021-01-12 ; UTA\n",
      "m3_2021-01-12.csv\n",
      "2021-01-12 ; LAL\n",
      "m4_2021-01-12.csv\n",
      "2021-01-12 ; SAS\n",
      "m5_2021-01-12.csv\n",
      "2021-01-12 ; IND\n",
      "m0_2021-01-13.csv\n",
      "2021-01-13 ; DAL\n",
      "m1_2021-01-13.csv\n",
      "2021-01-13 ; MIL\n",
      "m2_2021-01-13.csv\n",
      "2021-01-13 ; BKN\n",
      "m3_2021-01-13.csv\n",
      "2021-01-13 ; MEM\n",
      "m4_2021-01-13.csv\n",
      "2021-01-13 ; LAL\n",
      "m5_2021-01-13.csv\n",
      "2021-01-13 ; NOP\n",
      "m6_2021-01-13.csv\n",
      "2021-01-13 ; POR\n",
      "m0_2021-01-14.csv\n",
      "2021-01-14 ; MIA\n",
      "m1_2021-01-14.csv\n",
      "2021-01-14 ; CHA\n",
      "m2_2021-01-14.csv\n",
      "2021-01-14 ; HOU\n",
      "m3_2021-01-14.csv\n",
      "2021-01-14 ; GSW\n",
      "m4_2021-01-14.csv\n",
      "2021-01-14 ; IND\n"
     ]
    }
   ],
   "source": [
    "    for root, dossier, files in os.walk(dossierBase) : \n",
    "        for f in files :\n",
    "            id_type_match=0\n",
    "            id_saison=1\n",
    "            if 'equipe' in f and f.endswith('.csv'): \n",
    "                continue\n",
    "            elif 'equipe' not in f and f.endswith('.csv'):\n",
    "                #recuperer l'id_match : \n",
    "                idMatch=c.sqlAlchemyConn.execute(\"SELECT last_value FROM donnees_source.match_id_match_seq\").fetchone()[0] \n",
    "                #recuperer l'identifiant du match dans le dossier contenant les fichiers\n",
    "                groupe=f.split('_')[0][1:]\n",
    "                #recuperer la date du match\n",
    "                date=f.split('_')[1][:-4]\n",
    "                print(f)\n",
    "                #lire le fichier csv du match, transformer pour remplir la table des matchs\n",
    "                dfMatchCsv=pd.read_csv(os.path.join(root,f)).rename(columns={'equipe':'id_equipe'})\n",
    "                equipeExt=dfMatchCsv.iloc[0].id_equipe\n",
    "                equipeDom=dfMatchCsv.iloc[1].id_equipe\n",
    "                dfMatchBdd=pd.DataFrame({'id_saison':[id_saison],\n",
    "                                      'date_match':[date], \n",
    "                                      'equipe_domicile':[equipeDom], \n",
    "                                      'equipe_exterieure':[equipeExt],\n",
    "                                      'id_type_match':[id_type_match],\n",
    "                                        'id_match':idMatch})\n",
    "                #melt la table csv pour remplir la table des scores de match\n",
    "                dfScoreMatch=dfMatchCsv.melt(id_vars=['id_equipe'], value_vars=['q1','q2','q3','q4','final'],\n",
    "                            var_name='id_periode', value_name='score_periode').sort_values('id_equipe')\n",
    "                dfScoreMatch['id_match']=idMatch\n",
    "                \n",
    "                #maintenant il faut lire les fichiers stats_equipe associés\n",
    "                for i in (0,1) : \n",
    "                    nomFichierEquipe=f'm{groupe}_equipe{i}_{date}.csv'\n",
    "                    dfStatsJoueursCsv=pd.read_csv(os.path.join(root,nomFichierEquipe))\n",
    "                    idEquipe=dfMatchCsv.loc[i].id_equipe\n",
    "                    print(f'{date} ; {idEquipe}')\n",
    "                    \n",
    "                    #pensez à enlever du fichier source les joueurs n'ayant pas joué avant de creer la df des statsJoueur: \n",
    "                    dfStatsJoueursActifCsv=dfStatsJoueursCsv.loc[~dfStatsJoueursCsv['dnp']]\n",
    "                    \n",
    "                    #le pb ça va etre de recuperer les id_joueurs, va falloir telecharger d'abords la table de correspondance\n",
    "                    #faire la jointure en amont et ensuite on bascule tout le monde\n",
    "                    dfJoueursBdd=pd.read_sql('select id_joueur, nom_simple from donnees_source.joueur',c.sqlAlchemyConn)\n",
    "                    dfJoueursTot=dfStatsJoueursActifCsv.merge(dfJoueursBdd, on='nom_simple', how='left')                \n",
    "\n",
    "                    #pensez à checker si tous les joueurs sont présents dans la base joueur, et les ajouter si ils n'y sont pas\n",
    "                    dfJoueurInconnus=dfJoueursTot.loc[dfJoueursTot.id_joueur.isna()]\n",
    "                    if not dfJoueurInconnus.empty : \n",
    "                        dfJoueurInconnus=dfJoueurInconnus[['nom']]\n",
    "                        #basculer dans Bdd\n",
    "                        #dfJoueurInconnus.to_sql('joueur', c.sqlAlchemyConn, schema='donnees_source', if_exists='append', index=False)\n",
    "                        print(f'nouveau joueur : {dfJoueurInconnus.nom.tolist()} equipe {i}')\n",
    "\n",
    "                    #refaire un import et jointure au cas où des joueurs aient été ajoutés dans table joueurs, idem pour les contrats\n",
    "                    dfJoueursBddFinal=pd.read_sql('select id_joueur, nom_simple from donnees_source.joueur',c.sqlAlchemyConn)\n",
    "                    dfJoueursTot=dfStatsJoueursActifCsv.merge(dfJoueursBddFinal, on='nom_simple')\n",
    "                    \n",
    "                    \n",
    "                    #contrat : \n",
    "                    #1.verifier si id_joueur dans la base contrat : \n",
    "                    dfJoueurSansContrat=dfJoueursTot.loc[~dfJoueursTot.id_joueur.isin(dfContratBdd.id_joueur.tolist())]\n",
    "                    if not dfJoueurSansContrat.empty : #joueur sans contrat\n",
    "                        dfNewContrat=pd.DataFrame({'id_joueur':dfJoueurSansContrat.id_joueur.tolist(),'id_equipe':idEquipe,'date_debut_contrat':date})\n",
    "                        dfNewContrat.to_sql('contrat',c.sqlAlchemyConn, schema='donnees_source', if_exists='append', index=False)\n",
    "                    #joueur avec contrat : \n",
    "                    #jointure entre la table contratBdd et celle du match sur id_joueur pour comparer les equipes\n",
    "                    \n",
    "                    \"\"\"if not dfContratBdd.empty : \n",
    "                        dfContratJoueurMatch=dfContratBdd.merge(dfJoueursTot[['id_joueur']], on='id_joueur')\n",
    "                        dfContratJoueurChange=dfContratJoueurMatch.loc[dfContratJoueurMatch.id_equipe!=idEquipe]\n",
    "                        if not dfContratJoueurChange.empty: #si un joueur a changé d'équipe\n",
    "                            dateFinContrat=pd.to_datetime(date)-pd.Timedelta(1,'day').strftime('%Y-%m-%d')\n",
    "                            #il faut update la table avec la valeur de date en date_fin_contrat\n",
    "                            c.sqlAlchemyConn.execute(f\"UPDATE donnees_source.contrat SET date_fin_contrat = {dateFinContrat} WHERE id_contrat in ({','.join(dfContratJoueurChange.id_contrat.tolist())})\")\n",
    "                            #et inserer de nouvelle lignes\n",
    "                            pd.DataFrame({'id_joueur':dfContratJoueurChange.id_joueur.tolist(),'id_equipe':idEquipe,'date_debut_contrat':date}).to_sql(\n",
    "                                      'contrat',c.sqlAlchemyConn, schema='donnees_source', if_exists='append', index=False)\"\"\"\n",
    "                            \n",
    "                    \n",
    "\n",
    "                    #checker si des joueurs sont notés blessé et ne sont pas déjà dans la base blessure\n",
    "                    dfJoueursBlesses=dfStatsJoueursCsv.loc[dfStatsJoueursCsv['blesse']]\n",
    "                    rqtBlessesEncours=\"\"\"select b.*,j.nom \n",
    "                                          from donnees_source.joueur j JOIN donnees_source.blessure b ON j.id_joueur=b.id_joueur \n",
    "                                          WHERE b.date_guerison IS NULL\"\"\"\n",
    "                    dfJoueursBlessesBdd=pd.read_sql(rqtBlessesEncours,c.sqlAlchemyConn)\n",
    "                    if not dfJoueursBlesses.empty : #si des joueurs blesses, verifier qu'ils ne sont pas déjà presents dans la base\n",
    "                        if not dfJoueursBlesses.loc[~dfJoueursBlesses.nom.isin(dfJoueursBlessesBdd)].empty : \n",
    "                            #dfJoueursBlesses[['id_joueur']].assign(date_blessure=date).to_sql('blessure', c.sqlAlchemyConn, schema='donnees_source', if_exists='append', index=False)\n",
    "                            #print(f'blesse : {dfJoueursBlesses.nom.tolist()}')\n",
    "                            pass\n",
    "                            \n",
    "                    #checker si des joueurs ayant joué étaient noté blessé mais sont revenus\n",
    "\n",
    "                    #ensuite mettre en forme les stats de joueurs\n",
    "                    dfStatsJoueursBdd=dfJoueursTot[['minute', 'points', 'rebonds', 'passes_dec', 'steal',\n",
    "                       'contres', 'tir_reussi', 'tir_tentes', 'pct_tir', 'trois_pt_r',\n",
    "                       'trois_pt_t', 'pct_3_pt', 'lanc_frc_r', 'lanc_frc_t', 'pct_lfrc',\n",
    "                       'rebonds_o', 'rebonds_d', 'ball_perdu', 'faute_p', 'plus_moins', 'dnp',\n",
    "                       'blesse', 'score_ttfl', 'id_joueur']].copy()\n",
    "                    dfStatsJoueursBdd['id_match']=idMatch\n",
    "                    break\n",
    "        else :\n",
    "            continue\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfJoueurSansContrat.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_joueur</th>\n",
       "      <th>id_equipe</th>\n",
       "      <th>date_debut_contrat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>272</td>\n",
       "      <td>BKN</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211</td>\n",
       "      <td>BKN</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>330</td>\n",
       "      <td>BKN</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>BKN</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>306</td>\n",
       "      <td>BKN</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>88</td>\n",
       "      <td>BKN</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>500</td>\n",
       "      <td>BKN</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>348</td>\n",
       "      <td>BKN</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>256</td>\n",
       "      <td>BKN</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>467</td>\n",
       "      <td>BKN</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>452</td>\n",
       "      <td>BKN</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>147</td>\n",
       "      <td>BKN</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>363</td>\n",
       "      <td>BKN</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>342</td>\n",
       "      <td>BKN</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>323</td>\n",
       "      <td>BKN</td>\n",
       "      <td>2020-12-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id_joueur id_equipe date_debut_contrat\n",
       "0         272       BKN         2020-12-22\n",
       "1         211       BKN         2020-12-22\n",
       "2         330       BKN         2020-12-22\n",
       "3         200       BKN         2020-12-22\n",
       "4         306       BKN         2020-12-22\n",
       "5          88       BKN         2020-12-22\n",
       "6         500       BKN         2020-12-22\n",
       "7         348       BKN         2020-12-22\n",
       "8         256       BKN         2020-12-22\n",
       "9         467       BKN         2020-12-22\n",
       "10        452       BKN         2020-12-22\n",
       "11        147       BKN         2020-12-22\n",
       "12        363       BKN         2020-12-22\n",
       "13        342       BKN         2020-12-22\n",
       "14        323       BKN         2020-12-22"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNewContrat.loc[dfNewContrat.date_debut_contrat==dfNewContrat.groupby('id_joueur').date_debut_contrat.transform('max')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMatchCsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "idEquipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MetaData(bind=None)\n"
     ]
    }
   ],
   "source": [
    "with ct.ConnexionBdd('basket','maison') as c:\n",
    "    meta = MetaData()\n",
    "    meta.reflect(bind=c.sqlAlchemyConn)\n",
    "    print(meta)\n",
    "    for table in reversed(meta.sorted_tables):\n",
    "        print(meta,table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetaData(bind=None)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. exemple de blessure\n",
    "le joueur Markelle Fultz s'est fait une rupture des ligaments croisé, exemple d'insertion dans la table blessure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomJoueurBlesse='Markelle Fultz'\n",
    "idTypeBlessure=1\n",
    "dateBlessure='2021-06-01'\n",
    "requeteBlessure = f\"\"\"insert into donnees_source.blessure(id_joueur,id_type_blessure,date_blessure) \n",
    "             select id_joueur,{idTypeBlessure},{dateBlessure} from donnees_source.joueur where lower(nom)=lower{nomJoueurBlesse}\"\"\"\n",
    "with ct.ConnexionBdd('basket','maison') as c : \n",
    "    c.execute(c.sqlAlchemyConn,requeteBlessure)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
